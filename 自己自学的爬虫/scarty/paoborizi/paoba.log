2020-04-16 01:51:03 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 01:51:03 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 01:51:03 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 01:51:03 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 01:51:03 [scrapy.extensions.telnet] INFO: Telnet Password: 848c1c87220cb0a8
2020-04-16 01:51:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-04-16 01:51:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 01:51:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 01:51:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 01:51:03 [scrapy.core.engine] INFO: Spider opened
2020-04-16 01:51:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 01:51:03 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 01:51:03 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 01:51:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 01:51:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 12, in parse
    html = etree.HTML(response.content)
AttributeError: 'HtmlResponse' object has no attribute 'content'
2020-04-16 01:51:03 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 01:51:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.350627,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 8, 51, 3, 702358),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54288384,
 'memusage/startup': 54288384,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 4, 16, 8, 51, 3, 351731)}
2020-04-16 01:51:03 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 01:51:42 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 01:51:42 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 01:51:42 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 01:51:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 01:51:42 [scrapy.extensions.telnet] INFO: Telnet Password: d2f0affa19c61620
2020-04-16 01:51:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 01:51:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 01:51:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 01:51:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 01:51:42 [scrapy.core.engine] INFO: Spider opened
2020-04-16 01:51:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 01:51:42 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 01:51:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 01:51:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 01:51:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 12, in parse
    html = etree.HTML(response.content)
AttributeError: 'HtmlResponse' object has no attribute 'content'
2020-04-16 01:51:42 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 01:51:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.330921,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 8, 51, 42, 525823),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54292480,
 'memusage/startup': 54292480,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 4, 16, 8, 51, 42, 194902)}
2020-04-16 01:51:42 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 01:53:40 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 01:53:40 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 01:53:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 01:53:40 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 01:53:40 [scrapy.extensions.telnet] INFO: Telnet Password: 699c09554e71e7f2
2020-04-16 01:53:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 01:53:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 01:53:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 01:53:40 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 01:53:40 [scrapy.core.engine] INFO: Spider opened
2020-04-16 01:53:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 01:53:40 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 01:53:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 01:53:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 01:53:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 12, in parse
    html = etree.HTML(response.content)
AttributeError: 'HtmlResponse' object has no attribute 'content'
2020-04-16 01:53:40 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 01:53:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.466642,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 8, 53, 40, 930510),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 53665792,
 'memusage/startup': 53665792,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 4, 16, 8, 53, 40, 463868)}
2020-04-16 01:53:40 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 01:54:18 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 01:54:18 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 01:54:18 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 01:54:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 01:54:18 [scrapy.extensions.telnet] INFO: Telnet Password: d756bd35b68a3017
2020-04-16 01:54:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole']
2020-04-16 01:54:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 01:54:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 01:54:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 01:54:19 [scrapy.core.engine] INFO: Spider opened
2020-04-16 01:54:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 01:54:19 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 01:54:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 01:54:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 01:54:19 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 01:54:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.57424,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 8, 54, 19, 587139),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 53846016,
 'memusage/startup': 53846016,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 8, 54, 19, 12899)}
2020-04-16 01:54:19 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 01:54:37 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 01:54:37 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 01:54:37 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 01:54:37 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 01:54:37 [scrapy.extensions.telnet] INFO: Telnet Password: a95e3b8baf268ef1
2020-04-16 01:54:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2020-04-16 01:54:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 01:54:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 01:54:37 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 01:54:37 [scrapy.core.engine] INFO: Spider opened
2020-04-16 01:54:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 01:54:37 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 01:54:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 01:54:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 01:54:37 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 01:54:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.318073,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 8, 54, 37, 744711),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54153216,
 'memusage/startup': 54153216,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 8, 54, 37, 426638)}
2020-04-16 01:54:37 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 02:02:38 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 02:02:38 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 02:02:38 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 02:02:38 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 02:02:38 [scrapy.extensions.telnet] INFO: Telnet Password: 8c0b98637c39a28a
2020-04-16 02:02:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 02:02:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 02:02:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 02:02:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 02:02:38 [scrapy.core.engine] INFO: Spider opened
2020-04-16 02:02:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 02:02:38 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 02:02:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 02:02:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 02:02:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 20, in parse
    detail_url = urljoin(self.allowed_domains,url)
  File "/usr/lib/python3.5/urllib/parse.py", line 435, in urljoin
    base, url, _coerce_result = _coerce_args(base, url)
  File "/usr/lib/python3.5/urllib/parse.py", line 111, in _coerce_args
    raise TypeError("Cannot mix str and non-str arguments")
TypeError: Cannot mix str and non-str arguments
2020-04-16 02:02:38 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 02:02:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.382269,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 9, 2, 38, 808641),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54349824,
 'memusage/startup': 54349824,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2020, 4, 16, 9, 2, 38, 426372)}
2020-04-16 02:02:38 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 02:03:37 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 02:03:37 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 02:03:37 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 02:03:37 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 02:03:37 [scrapy.extensions.telnet] INFO: Telnet Password: a8d5fb45822f5d58
2020-04-16 02:03:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 02:03:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 02:03:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 02:03:37 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 02:03:37 [scrapy.core.engine] INFO: Spider opened
2020-04-16 02:03:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 02:03:37 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 02:03:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 02:03:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 02:03:38 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 02:03:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.334316,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 9, 3, 38, 259381),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54423552,
 'memusage/startup': 54423552,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 9, 3, 37, 925065)}
2020-04-16 02:03:38 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 02:29:35 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 02:29:35 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 02:29:35 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 02:29:35 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 02:29:35 [scrapy.extensions.telnet] INFO: Telnet Password: 2bbff1707faa1d13
2020-04-16 02:29:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-04-16 02:29:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 02:29:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 02:29:35 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 02:29:35 [scrapy.core.engine] INFO: Spider opened
2020-04-16 02:29:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 02:29:35 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 02:29:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 02:29:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 02:29:36 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 02:29:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.261307,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 9, 29, 36, 240895),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54247424,
 'memusage/startup': 54247424,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 9, 29, 35, 979588)}
2020-04-16 02:29:36 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 02:29:58 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 02:29:58 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 02:29:58 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 02:29:58 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 02:29:58 [scrapy.extensions.telnet] INFO: Telnet Password: d8593a5fde614571
2020-04-16 02:29:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-04-16 02:29:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 02:29:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 02:29:58 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 02:29:58 [scrapy.core.engine] INFO: Spider opened
2020-04-16 02:29:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 02:29:58 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 02:29:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 02:29:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 02:29:59 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 02:29:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 1.211192,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 9, 29, 59, 937743),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54366208,
 'memusage/startup': 54366208,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 9, 29, 58, 726551)}
2020-04-16 02:29:59 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 02:30:14 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 02:30:14 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 02:30:14 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 02:30:14 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 02:30:14 [scrapy.extensions.telnet] INFO: Telnet Password: 5ebcd5c9b3d250a1
2020-04-16 02:30:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2020-04-16 02:30:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 02:30:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 02:30:14 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 02:30:14 [scrapy.core.engine] INFO: Spider opened
2020-04-16 02:30:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 02:30:14 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 02:30:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 02:30:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 02:30:14 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 02:30:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.289238,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 9, 30, 14, 800677),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54370304,
 'memusage/startup': 54370304,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 9, 30, 14, 511439)}
2020-04-16 02:30:14 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 02:31:29 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 02:31:29 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 02:31:29 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 02:31:29 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 02:31:29 [scrapy.extensions.telnet] INFO: Telnet Password: f48ae9f72af0c1b4
2020-04-16 02:31:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2020-04-16 02:31:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 02:31:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 02:31:29 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 02:31:29 [scrapy.core.engine] INFO: Spider opened
2020-04-16 02:31:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 02:31:29 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 02:31:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 02:31:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 02:31:30 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 02:31:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.282934,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 9, 31, 30, 219743),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54173696,
 'memusage/startup': 54173696,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 9, 31, 29, 936809)}
2020-04-16 02:31:30 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 02:31:48 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 02:31:48 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 02:31:48 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 02:31:48 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 02:31:48 [scrapy.extensions.telnet] INFO: Telnet Password: af723c069db4d108
2020-04-16 02:31:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole']
2020-04-16 02:31:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 02:31:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 02:31:48 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 02:31:48 [scrapy.core.engine] INFO: Spider opened
2020-04-16 02:31:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 02:31:48 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 02:31:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 02:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 02:31:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 25, in parse
    href = li.css('h3>a::text').extract.first()
AttributeError: 'function' object has no attribute 'first'
2020-04-16 02:31:49 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 02:31:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.298572,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 9, 31, 49, 235072),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54435840,
 'memusage/startup': 54435840,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 4, 16, 9, 31, 48, 936500)}
2020-04-16 02:31:49 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 02:32:11 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 02:32:11 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 02:32:11 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 02:32:11 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 02:32:11 [scrapy.extensions.telnet] INFO: Telnet Password: 9413dff3bf0e6dec
2020-04-16 02:32:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 02:32:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 02:32:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 02:32:11 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 02:32:11 [scrapy.core.engine] INFO: Spider opened
2020-04-16 02:32:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 02:32:11 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 02:32:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 02:32:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 02:32:11 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 02:32:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.240933,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 9, 32, 11, 334986),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54341632,
 'memusage/startup': 54341632,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 9, 32, 11, 94053)}
2020-04-16 02:32:11 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 02:33:48 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 02:33:48 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 02:33:48 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 02:33:48 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 02:33:48 [scrapy.extensions.telnet] INFO: Telnet Password: b814769ad1b51640
2020-04-16 02:33:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 02:33:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 02:33:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 02:33:48 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 02:33:48 [scrapy.core.engine] INFO: Spider opened
2020-04-16 02:33:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 02:33:48 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 02:33:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 02:33:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 02:33:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 27, in parse
    title = li.css('h3>a::attr[href]').extract_first()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/parsel/selector.py", line 264, in css
    return self.xpath(self._css2xpath(query))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/parsel/selector.py", line 267, in _css2xpath
    return self._csstranslator.css_to_xpath(query)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/parsel/csstranslator.py", line 109, in css_to_xpath
    return super(HTMLTranslator, self).css_to_xpath(css, prefix)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/cssselect/xpath.py", line 192, in css_to_xpath
    for selector in parse(css))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/cssselect/parser.py", line 415, in parse
    return list(parse_selector_group(stream))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/cssselect/parser.py", line 428, in parse_selector_group
    yield Selector(*parse_selector(stream))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/cssselect/parser.py", line 454, in parse_selector
    next_selector, pseudo_element = parse_simple_selector(stream)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/cssselect/parser.py", line 487, in parse_simple_selector
    % pseudo_element)
  File "<string>", line None
cssselect.parser.SelectorSyntaxError: Got pseudo-element ::attr not at the end of a selector
2020-04-16 02:33:49 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 02:33:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.64183,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 9, 33, 49, 239494),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54317056,
 'memusage/startup': 54317056,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/SelectorSyntaxError': 1,
 'start_time': datetime.datetime(2020, 4, 16, 9, 33, 48, 597664)}
2020-04-16 02:33:49 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 02:35:14 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 02:35:14 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 02:35:14 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 02:35:14 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 02:35:14 [scrapy.extensions.telnet] INFO: Telnet Password: b6a193b9c98c76dc
2020-04-16 02:35:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2020-04-16 02:35:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 02:35:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 02:35:14 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 02:35:14 [scrapy.core.engine] INFO: Spider opened
2020-04-16 02:35:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 02:35:14 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 02:35:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 02:35:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 02:35:14 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 02:35:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.328022,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 9, 35, 14, 689555),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54177792,
 'memusage/startup': 54177792,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 9, 35, 14, 361533)}
2020-04-16 02:35:14 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 02:38:21 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 02:38:21 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 02:38:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 02:38:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 02:38:22 [scrapy.extensions.telnet] INFO: Telnet Password: de91fc32a8281ded
2020-04-16 02:38:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 02:38:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 02:38:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 02:38:22 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 02:38:22 [scrapy.core.engine] INFO: Spider opened
2020-04-16 02:38:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 02:38:22 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 02:38:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 02:38:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 02:38:22 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 02:38:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.338282,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 9, 38, 22, 548428),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54317056,
 'memusage/startup': 54317056,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 9, 38, 22, 210146)}
2020-04-16 02:38:22 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 02:38:43 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 02:38:43 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 02:38:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 02:38:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 02:38:43 [scrapy.extensions.telnet] INFO: Telnet Password: 929753601dd2fe36
2020-04-16 02:38:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 02:38:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 02:38:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 02:38:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 02:38:43 [scrapy.core.engine] INFO: Spider opened
2020-04-16 02:38:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 02:38:43 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 02:38:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 02:38:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 02:38:43 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 02:38:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.239726,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 9, 38, 43, 788264),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54411264,
 'memusage/startup': 54411264,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 9, 38, 43, 548538)}
2020-04-16 02:38:43 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 02:38:59 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 02:38:59 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 02:38:59 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 02:38:59 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 02:38:59 [scrapy.extensions.telnet] INFO: Telnet Password: 9a0d36de9eab75f3
2020-04-16 02:38:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 02:38:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 02:38:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 02:38:59 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 02:38:59 [scrapy.core.engine] INFO: Spider opened
2020-04-16 02:38:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 02:38:59 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 02:38:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 02:38:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 02:38:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 32, in parse
    nvum = li.xpath(".//li[@class='list-msg']//span[2]/text()").extrace_first()
AttributeError: 'SelectorList' object has no attribute 'extrace_first'
2020-04-16 02:38:59 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 02:38:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.377962,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 9, 38, 59, 849210),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54337536,
 'memusage/startup': 54337536,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 4, 16, 9, 38, 59, 471248)}
2020-04-16 02:38:59 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 02:39:08 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 02:39:08 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 02:39:08 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 02:39:08 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 02:39:08 [scrapy.extensions.telnet] INFO: Telnet Password: a1f76b50984b42c2
2020-04-16 02:39:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 02:39:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 02:39:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 02:39:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 02:39:08 [scrapy.core.engine] INFO: Spider opened
2020-04-16 02:39:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 02:39:08 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 02:39:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 02:39:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 02:39:09 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 02:39:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.682509,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 9, 39, 9, 101115),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54382592,
 'memusage/startup': 54382592,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 9, 39, 8, 418606)}
2020-04-16 02:39:09 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:03:17 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:03:17 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:03:17 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:03:17 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:03:17 [scrapy.extensions.telnet] INFO: Telnet Password: 2cebc3ff9a0ac2bb
2020-04-16 03:03:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 03:03:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:03:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:03:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:03:17 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:03:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:03:17 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 03:03:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:03:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:03:18 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'www.jcodecraeer.com': <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
2020-04-16 03:03:18 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:03:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.324923,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 3, 18, 116189),
 'log_count/DEBUG': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54218752,
 'memusage/startup': 54218752,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 10, 3, 17, 791266)}
2020-04-16 03:03:18 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:04:24 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:04:24 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:04:24 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:04:24 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:04:24 [scrapy.extensions.telnet] INFO: Telnet Password: a96f7c149d0f217f
2020-04-16 03:04:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats']
2020-04-16 03:04:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:04:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:04:24 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:04:24 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:04:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:04:24 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 03:04:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:04:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:04:24 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'www.jcodecraeer.com': <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
2020-04-16 03:04:24 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:04:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.286095,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 4, 24, 639970),
 'log_count/DEBUG': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54247424,
 'memusage/startup': 54247424,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 10, 4, 24, 353875)}
2020-04-16 03:04:24 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:05:53 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:05:53 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:05:53 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:05:53 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:05:53 [scrapy.extensions.telnet] INFO: Telnet Password: 4ba6bd2680cdf097
2020-04-16 03:05:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats']
2020-04-16 03:05:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:05:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:05:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:05:53 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:05:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:05:53 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 03:05:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:05:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:05:53 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'www.jcodecraeer.com': <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
2020-04-16 03:05:53 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:05:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.366019,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 5, 53, 832642),
 'log_count/DEBUG': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 54091776,
 'memusage/startup': 54091776,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 10, 5, 53, 466623)}
2020-04-16 03:05:53 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:07:34 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:07:34 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:07:34 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:07:34 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:07:34 [scrapy.extensions.telnet] INFO: Telnet Password: 3543ce2ad0b0d1cf
2020-04-16 03:07:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2020-04-16 03:07:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:07:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:07:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:07:34 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:07:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:07:34 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 03:07:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:07:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:07:36 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'www.jcodecraeer.com': <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
2020-04-16 03:07:36 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:07:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 1.109228,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 7, 36, 54104),
 'log_count/DEBUG': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 47689728,
 'memusage/startup': 47689728,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 10, 7, 34, 944876)}
2020-04-16 03:07:36 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:07:41 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:07:41 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:07:41 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:07:41 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:07:41 [scrapy.extensions.telnet] INFO: Telnet Password: a29cc74cb000e2de
2020-04-16 03:07:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage']
2020-04-16 03:07:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:07:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:07:41 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:07:41 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:07:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:07:41 [py.warnings] WARNING: /home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py:61: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry http://www.jcodecraeer.com/ in allowed_domains.
  warnings.warn(message, URLWarning)

2020-04-16 03:07:41 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:07:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:07:41 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'www.jcodecraeer.com': <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
2020-04-16 03:07:42 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:07:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.266906,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 7, 42, 8063),
 'log_count/DEBUG': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'memusage/max': 53936128,
 'memusage/startup': 53936128,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 10, 7, 41, 741157)}
2020-04-16 03:07:42 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:14:33 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:14:33 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:14:33 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:14:33 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:14:33 [scrapy.extensions.telnet] INFO: Telnet Password: 5b47e2b276768646
2020-04-16 03:14:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 03:14:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:14:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:14:33 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:14:33 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:14:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:14:33 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:14:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:14:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 117, in iter_errback
    yield next(it)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 38, in parse
    yield scrapy.Request(url=detail_url,meta={"item":item},callback=self.detail_parse)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/http/request/__init__.py", line 25, in __init__
    self._set_url(url)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/http/request/__init__.py", line 68, in _set_url
    raise ValueError('Missing scheme in request url: %s' % self._url)
ValueError: Missing scheme in request url: a/okaianzhufa/anzhuozixun/2017/1023/8634.html
2020-04-16 03:14:34 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:14:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.381286,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 14, 34, 1461),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 54140928,
 'memusage/startup': 54140928,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2020, 4, 16, 10, 14, 33, 620175)}
2020-04-16 03:14:34 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:20:41 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:20:41 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:20:41 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:20:41 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:20:41 [scrapy.extensions.telnet] INFO: Telnet Password: ba6d2137967a1a96
2020-04-16 03:20:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 03:20:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:20:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:20:41 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:20:41 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:20:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:20:41 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:20:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:20:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 117, in iter_errback
    yield next(it)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 38, in parse
    yield scrapy.Request(url=list(detail_url),meta={"item":item},callback=self.detail_parse)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/http/request/__init__.py", line 25, in __init__
    self._set_url(url)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/http/request/__init__.py", line 62, in _set_url
    raise TypeError('Request url must be str or unicode, got %s:' % type(url).__name__)
TypeError: Request url must be str or unicode, got list:
2020-04-16 03:20:41 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:20:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.234605,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 20, 41, 923670),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 53641216,
 'memusage/startup': 53641216,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2020, 4, 16, 10, 20, 41, 689065)}
2020-04-16 03:20:41 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:21:05 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:21:05 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:21:05 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:21:05 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:21:05 [scrapy.extensions.telnet] INFO: Telnet Password: aea48f62b79b9ce3
2020-04-16 03:21:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole']
2020-04-16 03:21:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:21:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:21:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:21:05 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:21:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:21:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:21:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:21:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 117, in iter_errback
    yield next(it)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 38, in parse
    yield scrapy.Request(url=detail_url,meta={"item":item},callback=self.detail_parse)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/http/request/__init__.py", line 25, in __init__
    self._set_url(url)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/http/request/__init__.py", line 68, in _set_url
    raise ValueError('Missing scheme in request url: %s' % self._url)
ValueError: Missing scheme in request url: a/anzhuokaifa/anzhuozixun/2017/1023/8634.html
2020-04-16 03:21:05 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:21:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.204599,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 21, 5, 346255),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 53809152,
 'memusage/startup': 53809152,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2020, 4, 16, 10, 21, 5, 141656)}
2020-04-16 03:21:05 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:21:42 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:21:42 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:21:42 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:21:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:21:42 [scrapy.extensions.telnet] INFO: Telnet Password: 2fe85b5a3650fc21
2020-04-16 03:21:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 03:21:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:21:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:21:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:21:42 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:21:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:21:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:21:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:21:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 117, in iter_errback
    yield next(it)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 38, in parse
    yield scrapy.Request(url=detail_url,meta={"item":item},callback=self.detail_parse)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/http/request/__init__.py", line 25, in __init__
    self._set_url(url)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/http/request/__init__.py", line 68, in _set_url
    raise ValueError('Missing scheme in request url: %s' % self._url)
ValueError: Missing scheme in request url: a/anzhuokaifa/anzhuozixun/2017/1023/8634.html
2020-04-16 03:21:42 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:21:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.192625,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 21, 42, 342277),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 54042624,
 'memusage/startup': 54042624,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2020, 4, 16, 10, 21, 42, 149652)}
2020-04-16 03:21:42 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:22:40 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:22:40 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:22:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:22:40 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:22:40 [scrapy.extensions.telnet] INFO: Telnet Password: 89ee18db5b73f094
2020-04-16 03:22:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 03:22:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:22:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:22:40 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:22:40 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:22:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:22:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:22:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:22:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 117, in iter_errback
    yield next(it)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 38, in parse
    yield scrapy.Request(url=detail_url,meta={"item":item},callback=self.detail_parse)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/http/request/__init__.py", line 25, in __init__
    self._set_url(url)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/http/request/__init__.py", line 68, in _set_url
    raise ValueError('Missing scheme in request url: %s' % self._url)
ValueError: Missing scheme in request url: a/anzhuokaifa/anzhuozixun/2017/1023/8634.html
2020-04-16 03:22:40 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:22:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.195143,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 22, 40, 474827),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 53809152,
 'memusage/startup': 53809152,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2020, 4, 16, 10, 22, 40, 279684)}
2020-04-16 03:22:40 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:23:02 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:23:02 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:23:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:23:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:23:02 [scrapy.extensions.telnet] INFO: Telnet Password: 97e22c467b475bdb
2020-04-16 03:23:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2020-04-16 03:23:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:23:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:23:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:23:02 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:23:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:23:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:23:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:23:04 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'www.jcodecraeer.com': <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
2020-04-16 03:23:04 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:23:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 2.198437,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 23, 4, 712260),
 'log_count/DEBUG': 2,
 'log_count/INFO': 10,
 'memusage/max': 53805056,
 'memusage/startup': 53805056,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 10, 23, 2, 513823)}
2020-04-16 03:23:04 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:23:43 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:23:43 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:23:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:23:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:23:43 [scrapy.extensions.telnet] INFO: Telnet Password: 182b9212a8a546db
2020-04-16 03:23:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage']
2020-04-16 03:23:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:23:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:23:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:23:43 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:23:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:23:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:23:43 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'www.jcodecraeer.com': <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
2020-04-16 03:23:43 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:23:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.213315,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 23, 43, 642289),
 'log_count/DEBUG': 2,
 'log_count/INFO': 10,
 'memusage/max': 53907456,
 'memusage/startup': 53907456,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 10, 23, 43, 428974)}
2020-04-16 03:23:43 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:25:57 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:25:57 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:25:57 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:25:57 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:25:57 [scrapy.extensions.telnet] INFO: Telnet Password: 0c71c79a8a90afdf
2020-04-16 03:25:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 03:25:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:25:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:25:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:25:57 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:25:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:25:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:25:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:25:58 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'www.jcodecraeer.com': <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
2020-04-16 03:25:58 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:25:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 8773,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.693059,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 25, 58, 622315),
 'log_count/DEBUG': 2,
 'log_count/INFO': 10,
 'memusage/max': 54153216,
 'memusage/startup': 54153216,
 'offsite/domains': 1,
 'offsite/filtered': 15,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 4, 16, 10, 25, 57, 929256)}
2020-04-16 03:25:58 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:28:10 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:28:10 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:28:10 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:28:11 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:28:11 [scrapy.extensions.telnet] INFO: Telnet Password: 2a5fa22aaae25b7b
2020-04-16 03:28:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-04-16 03:28:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:28:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:28:11 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:28:11 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:28:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:28:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:28:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:28:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:28:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:28:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:28:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:28:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:28:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:28:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:28:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:28:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:28:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:28:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:28:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:28:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:28:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:28:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:28:13 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:28:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 2.201635,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 28, 13, 325720),
 'log_count/DEBUG': 16,
 'log_count/INFO': 10,
 'memusage/max': 54169600,
 'memusage/startup': 54169600,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 10, 28, 11, 124085)}
2020-04-16 03:28:13 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:29:21 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:29:21 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:29:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:29:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:29:21 [scrapy.extensions.telnet] INFO: Telnet Password: 7ef45ca58607e6d7
2020-04-16 03:29:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage']
2020-04-16 03:29:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:29:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:29:21 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:29:21 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:29:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:29:21 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:23 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:29:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 2.129213,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 29, 23, 708208),
 'log_count/DEBUG': 16,
 'log_count/INFO': 10,
 'memusage/max': 54243328,
 'memusage/startup': 54243328,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 10, 29, 21, 578995)}
2020-04-16 03:29:23 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:29:43 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:29:43 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:29:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:29:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:29:43 [scrapy.extensions.telnet] INFO: Telnet Password: e96bc6ed5db02d86
2020-04-16 03:29:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 03:29:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:29:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:29:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:29:43 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:29:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:29:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:29:49 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:29:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 5.066508,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 29, 49, 39023),
 'log_count/DEBUG': 16,
 'log_count/INFO': 10,
 'memusage/max': 53874688,
 'memusage/startup': 53874688,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 10, 29, 43, 972515)}
2020-04-16 03:29:49 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:31:48 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:31:48 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:31:48 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:31:48 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:31:48 [scrapy.extensions.telnet] INFO: Telnet Password: 3f6832c33933decb
2020-04-16 03:31:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 03:31:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:31:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:31:48 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:31:48 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:31:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:31:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:31:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:31:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:31:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:31:50 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:31:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 1.760424,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 31, 50, 400586),
 'log_count/DEBUG': 16,
 'log_count/INFO': 10,
 'memusage/max': 54157312,
 'memusage/startup': 54157312,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 10, 31, 48, 640162)}
2020-04-16 03:31:50 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:32:23 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:32:23 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:32:23 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:32:23 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:32:23 [scrapy.extensions.telnet] INFO: Telnet Password: 7a477005519ab88f
2020-04-16 03:32:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2020-04-16 03:32:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:32:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:32:23 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:32:23 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:32:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:32:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:32:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:32:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:32:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:32:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:32:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:32:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:32:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:32:27 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:32:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 4.076214,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 32, 27, 559702),
 'log_count/DEBUG': 16,
 'log_count/INFO': 10,
 'memusage/max': 54153216,
 'memusage/startup': 54153216,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 10, 32, 23, 483488)}
2020-04-16 03:32:27 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:34:00 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:34:00 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:34:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:34:00 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:34:00 [scrapy.extensions.telnet] INFO: Telnet Password: b3c8605759a9aa3f
2020-04-16 03:34:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 03:34:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:34:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:34:00 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:34:00 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:34:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:34:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:34:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:34:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 43, in detail_parse
    content = response.xpath("//div[@class='articlecon clearfix']/text()").extract().replace('\t\n','')
AttributeError: 'list' object has no attribute 'replace'
2020-04-16 03:34:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 43, in detail_parse
    content = response.xpath("//div[@class='articlecon clearfix']/text()").extract().replace('\t\n','')
AttributeError: 'list' object has no attribute 'replace'
2020-04-16 03:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 43, in detail_parse
    content = response.xpath("//div[@class='articlecon clearfix']/text()").extract().replace('\t\n','')
AttributeError: 'list' object has no attribute 'replace'
2020-04-16 03:34:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 43, in detail_parse
    content = response.xpath("//div[@class='articlecon clearfix']/text()").extract().replace('\t\n','')
AttributeError: 'list' object has no attribute 'replace'
2020-04-16 03:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 43, in detail_parse
    content = response.xpath("//div[@class='articlecon clearfix']/text()").extract().replace('\t\n','')
AttributeError: 'list' object has no attribute 'replace'
2020-04-16 03:34:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 43, in detail_parse
    content = response.xpath("//div[@class='articlecon clearfix']/text()").extract().replace('\t\n','')
AttributeError: 'list' object has no attribute 'replace'
2020-04-16 03:34:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 43, in detail_parse
    content = response.xpath("//div[@class='articlecon clearfix']/text()").extract().replace('\t\n','')
AttributeError: 'list' object has no attribute 'replace'
2020-04-16 03:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 43, in detail_parse
    content = response.xpath("//div[@class='articlecon clearfix']/text()").extract().replace('\t\n','')
AttributeError: 'list' object has no attribute 'replace'
2020-04-16 03:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 43, in detail_parse
    content = response.xpath("//div[@class='articlecon clearfix']/text()").extract().replace('\t\n','')
AttributeError: 'list' object has no attribute 'replace'
2020-04-16 03:34:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 43, in detail_parse
    content = response.xpath("//div[@class='articlecon clearfix']/text()").extract().replace('\t\n','')
AttributeError: 'list' object has no attribute 'replace'
2020-04-16 03:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 43, in detail_parse
    content = response.xpath("//div[@class='articlecon clearfix']/text()").extract().replace('\t\n','')
AttributeError: 'list' object has no attribute 'replace'
2020-04-16 03:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 43, in detail_parse
    content = response.xpath("//div[@class='articlecon clearfix']/text()").extract().replace('\t\n','')
AttributeError: 'list' object has no attribute 'replace'
2020-04-16 03:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 43, in detail_parse
    content = response.xpath("//div[@class='articlecon clearfix']/text()").extract().replace('\t\n','')
AttributeError: 'list' object has no attribute 'replace'
2020-04-16 03:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 43, in detail_parse
    content = response.xpath("//div[@class='articlecon clearfix']/text()").extract().replace('\t\n','')
AttributeError: 'list' object has no attribute 'replace'
2020-04-16 03:34:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 43, in detail_parse
    content = response.xpath("//div[@class='articlecon clearfix']/text()").extract().replace('\t\n','')
AttributeError: 'list' object has no attribute 'replace'
2020-04-16 03:34:02 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:34:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 1.330793,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 34, 2, 300316),
 'log_count/DEBUG': 16,
 'log_count/ERROR': 15,
 'log_count/INFO': 10,
 'memusage/max': 54157312,
 'memusage/startup': 54157312,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'spider_exceptions/AttributeError': 15,
 'start_time': datetime.datetime(2020, 4, 16, 10, 34, 0, 969523)}
2020-04-16 03:34:02 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:34:52 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:34:52 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:34:52 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:34:52 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:34:52 [scrapy.extensions.telnet] INFO: Telnet Password: 1e8daf54301442df
2020-04-16 03:34:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2020-04-16 03:34:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:34:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:34:52 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:34:52 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:34:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:34:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:34:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:34:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:34:53 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:34:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 1.408809,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 34, 53, 620855),
 'log_count/DEBUG': 16,
 'log_count/INFO': 10,
 'memusage/max': 54145024,
 'memusage/startup': 54145024,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 10, 34, 52, 212046)}
2020-04-16 03:34:53 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:35:44 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:35:44 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:35:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:35:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:35:44 [scrapy.extensions.telnet] INFO: Telnet Password: f979a21d2976a08a
2020-04-16 03:35:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 03:35:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:35:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:35:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:35:44 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:35:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:35:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:35:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:35:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:35:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:35:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:35:45 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 0.932205,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 35, 45, 491988),
 'log_count/DEBUG': 16,
 'log_count/INFO': 10,
 'memusage/max': 54013952,
 'memusage/startup': 54013952,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 10, 35, 44, 559783)}
2020-04-16 03:35:45 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:36:08 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:36:08 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:36:08 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:36:08 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:36:08 [scrapy.extensions.telnet] INFO: Telnet Password: 86e7e90c57784d1b
2020-04-16 03:36:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2020-04-16 03:36:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:36:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:36:08 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:36:08 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:36:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:36:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:36:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:36:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:09 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:36:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 1.458208,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 36, 9, 527541),
 'log_count/DEBUG': 16,
 'log_count/INFO': 10,
 'memusage/max': 53866496,
 'memusage/startup': 53866496,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 10, 36, 8, 69333)}
2020-04-16 03:36:09 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:36:43 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:36:43 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:36:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:36:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:36:43 [scrapy.extensions.telnet] INFO: Telnet Password: 1f8e7b295bdfaca5
2020-04-16 03:36:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole']
2020-04-16 03:36:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:36:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:36:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:36:43 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:36:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:36:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:36:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:36:45 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:36:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 1.662559,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 36, 45, 446747),
 'log_count/DEBUG': 16,
 'log_count/INFO': 10,
 'memusage/max': 53678080,
 'memusage/startup': 53678080,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 10, 36, 43, 784188)}
2020-04-16 03:36:45 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:54:44 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:54:44 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:54:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:54:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:54:44 [scrapy.extensions.telnet] INFO: Telnet Password: a8b19e118c33788f
2020-04-16 03:54:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-04-16 03:54:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:54:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:54:45 [twisted] CRITICAL: Unhandled error in Deferred:
2020-04-16 03:54:45 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/crawler.py", line 89, in crawl
    self.engine = self._create_engine()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/crawler.py", line 103, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/middleware.py", line 35, in from_settings
    mw = create_instance(mwcls, settings, crawler)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/misc.py", line 150, in create_instance
    return objcls(*args, **kwargs)
TypeError: __init__() missing 5 required positional arguments: 'host', 'user', 'password', 'database', and 'prot'
2020-04-16 03:55:10 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:55:10 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:55:10 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:55:10 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:55:10 [scrapy.extensions.telnet] INFO: Telnet Password: eda32d3c66832b68
2020-04-16 03:55:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 03:55:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:55:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:55:10 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-16 03:55:10 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:55:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:55:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  bug  Play store  app '
            'bugapp\xa0'
            'HackerOne '
            'issue1000app\xa0'
            'Dropbox, Duolingo, Line, Snapchat, Tinder, Alibaba, Mail.ru  '
            'Headspace '
            'appappappbughttps://www.engadget.com/2017/10/20/google-bug-bounty-program-android-apps/\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Windows 10 SWindows '
            '10 Windows 10 SWindows RTWindows 10 '
            'SEdgeBingGoogle '
            'ChromeWindows StoreZDNetWindows '
            'StoreDekstop BridgeWindows '
            'StoreEdgeUWP '
            'EdgeHTMLJavaScriptWindows '
            'StoreWindows PlatformHTMLJavaScriptWindows '
            'StoreWindows '
            '10 '
            'ProiOSWebKitiOS '
            'ChromebookChromeGoogleChrome '
            'OSAndroidWindowsChromeFirefoxWindows '
            '10Windows 10 SChromebook '
            'EdgeChromeFirefoxcnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t \xa0 \xa0 \xa0 \xa0'
            'GoogleUdacity75000AndroidGoogleUdacity20152016100010000Google '
            'EMEAMatt '
            'BrittinUdacity75000Google202050AndroidWebUdacity15000cnbetahttp://www.cnbeta.com/articles/tech/648715.htm\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            '517I/Ohttps://events.google.com/io/\xa0'
            'GoogleI/O Live '
            'Widget/517-19I/Oyoutubef '
            'q '
            'https://events.google.com/io/widget/?utm_source=google&utm_medium=social&utm_campaign=gplus\xa0'
            '\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Fuchsia Git '
            ' UI Android  '
            'Chrome OS Fuchsia  Linux    '
            '"Magenta" FuchsiaLinux  GPL \xa0'
            'BSD 3 clause,\xa0MIT, \xa0Apache 2.0\xa0 Linux '
            ' Android  Linux  Google Pixel '
            ' 2014  Linux Kernel 3.18 \xa0Magenta '
            ' Fuchsia '
            ' Android '
            'Fuchsia '
            "\xa0Google's Flutter SDK\xa0"
            ' Android  iOS Flutter app  Dart '
            'Flutter SDK "Escher"\xa0Vulkan '
            ' shadow-heavy Material Design '
            'Fuchsia  UI  ArmadilloFuchsia  Flutter '
            'SDK Armadillo  Google  Fuchsia '
            ' UI  Android APK  Android  UI '
            '20% '
            'Fuchsia  Fuchsia IRC Fuchsia  Travis '
            'Geiselbrecht  20% '
            'Android '
            ' UI  '
            'Dart  Linux  GPL Java \xa0'
            'Oracle  Android  '
            'Android  Fuchsia  2020 '
            'Fuchsia '
            'arsTECHNICAhttp://www.oschina.net/news/84594/google-fuchsia-smartphone-os-dumps-linux-has-a-wild-new-ui\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'appAndroid '
            'batbatapphttps://green-android.org/app-convention.html\xa0'
            'AndroidAndroidAndroidAndroidAndroidAndroidGitHub '
            'issue trackerAndroidAndroid '
            'OAndroidTarget '
            'SDK Version >= 24 (Android 7.0)Project SvelteAndroid '
            '7READ_PHONE_STATEIMEIAndroid '
            '6.0Android\xa0'
            'SDKCPUIOCPUAlarmJobScheduler301CPUGoogleProject '
            'Volta121Android4.4 '
            '(Background-free)CPUIO '
            'Android O '
            '(Background-free)Android '
            'O3PendingIntentJobSchedulerAndroid '
            '5.0AndroidManifest.xmlAndroid '
            'OAndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xmlandroid.net.conn.CONNECTIVITY_CHANGE\xa0'
            'Android '
            '7android.hardware.action.NEW_PICTURE\xa0'
            'android.hardware.action.NEW_VIDEO\xa0'
            'android.net.wifi.SCAN_RESULTS\xa0 LocationManager '
            'android.intent.action.USER_PRESENT\xa0'
            'android.intent.action.ACTION_POWER_CONNECTED\xa0 '
            'JobScheduler '
            'android.intent.action.ACTION_POWER_DISCONNECTED\xa0 '
            'JobScheduler android.intent.action.MEDIA_\xa0'
            'AndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xml<receiver\xa0...\xa0'
            'android:enabled="@bool/until_api_21">/src/main/res/values/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">true</bool>\n'
            '</resources>/src/main/res/values-v21/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">false</bool>\n'
            '</resources>Android 4.4 / '
            'AndroidAndroid '
            '4.4Storage Access '
            'FrameworkAPITFUSB '
            'OTGNASDropboxGoogle '
            'Drive4.4AndroidAndroid '
            '4.4<uses-permission '
            'android:name="android.permission.WRITE_EXTERNAL_STORAGE" '
            'android:maxSdkVersion="18" '
            '/>Context.getExternalFilesDir()\xa0'
            'Context.getExternalCacheDir()\xa0APIAndroid '
            '4.4Android '
            '4.4Google '
            'PlayGoogle PlayGoogle '
            'PlayAndroidAndroidGoogle '
            'PlayAndroidGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'Play\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Java  James Gosling\xa0 AWS '
            'James Gosling  Facebook  '
            'Gosling  AWS '
            'Gosling  IoT  IoT '
            'James Gosling  Sun Microsystems  Java '
            ' Sun  '
            'Google Liquid Robotics  Wave '
            'GliderGosling '
            ' '
            '\xa0'
            '[http://www.oschina.net]https://www.oschina.net/news/85108/aws-signs-java-father-james-gosling\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Android  Android '
            'Android  Google '
            'Android Google  4 Google  10  '
            'Google Pixel  Android Nought  7%  '
            'Android 7.1  0.5%2015  Android 6.0  2014  '
            'Android 5.0  31.2%  32 % Android N Android O '
            'googleGoogle  Android N '
            ' Android O '
            ' Android '
            ' Android O  Android '
            'Google Project\xa0Treble Google  '
            'Project Treble  Android  OEM '
            'Android  Google '
            ' Android '
            'Android O  '
            '9to5google Google  '
            'Android  QualcomMediatek LG '
            ' Android '
            ' '
            'Android  Google Google '
            ' Google Pixel  Nexus  cdnforo Project Treble  '
            'Android Google '
            'Vendor '
            'ImplementaTIonOEM '
            ' '
            'AndroidfonpitOEM '
            'Google  OEM  '
            'Android AOSPOEM  '
            'Android  OEM  AndroidAndroid O '
            'Google Project Treble Android O Android '
            'Google I/O 2017  5  18 '
            'ifanrandroidcommunityhttp://www.ifanr.com/835683\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'AOL50Oath15%35%Altaba19952261322AOL50Oath15%35%AltabaAltaba6002300Verizon200015%1995 '
            'David FiloCEO2001Terry '
            'Semel10001.62Verizon748.344.82300300200020125Tumblr2300254%1553.12112%Terry '
            'SemelCarol '
            'BartzFacebookInstagramSnapchat199532100022SlackWhatsAppVerizon*************************************************************323Verizon55106.5150YahooMozillaAppFantasy2012iOSAndroid41400SSLHTML5HTTPS5201320142Mavens '
            'GAAP2042%20122102011GAAP1510BrightRollFlurry1720127451805303501028.6427%IPO1.22IPO908FYIPB&JHackdays48%25%17.5770Yaho-o-ooMarissahttp://netsmell.com/post/yahoo-45b-acquired-by.html\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t splash '
            'screenappappAndroid '
            'Oreo\xa0Android 8.0\xa0\xa0splash screen '
            'APIAPIdrawableappActivityAndroid '
            'OreodrawableSplashActivityAPI\xa0'
            'Android Developers\xa0'
            '413AOSPAndroid '
            'O\xa0AOSP commit\xa0'
            'APIAndroid '
            'Oreo\xa0APIAndroid '
            'Open Source ProjectAndroid Oreo Adds a Splash Screen API so '
            'Developers can Easily Build App Loading Screens\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  GMS '
            'OPPOvivoUnified '
            'Push '
            'ServiceUPSAPNS '
            'App  App '
            ' '
            'Android '
            'AppApp '
            'API  API '
            'AppSDKSDK '
            'ROM API '
            'SDKIT\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t MinecraftXbox One '
            'X4K.jpgE3 '
            '2017MinecraftGears of War 4Forza '
            'Horizon 3Killer InstinctHalo Wars 24KSuper Duper '
            'Graphics...XD4K '
            '... 4K '
            'Better '
            'TogetherMinecraftMinecraftSuper '
            'Duper Graphics packXbox One '
            'X4KPCMinecraftMinecraftMinecraftSkinMinecraft\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'WannaCryWannaCry150NSAWannaCryNSA(moderate '
            'confidence)WannaCryWannaCryNSAIPLazarus '
            'GroupWannaCry300cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Google  Android 8.0 '
            'Oreo Android Beta Google  Oreo '
            'Google  Nexus  Pixel  '
            'Android 8.0 Google  '
            'EssentialHTCKyoceraMotorolaHMD '
            'GlobalNokia '
            'Android 8.0  2018  Pixel  '
            'HTC  LG  HTC  U11  Android '
            '8.0cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t AndroidAndy '
            'RubinEssential PhoneEssential '
            'PhoneEssential '
            'PhoneEssential '
            'Phone8354GB128GB5.712560 x 1312 '
            'QHD19:103040mAh360UHD '
            '(3840x1920) 30Fps/DockEssential '
            'Phone1200 '
            '8004KEssential7.1.1ITEssential '
            'Phone3.5mmUSB-C5.069947893607495132 '
            'it\xa0http://mt.sohu.com/20170530/n495020791.shtml\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:12 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:55:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 2.602884,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 55, 12, 772776),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/INFO': 10,
 'memusage/max': 55136256,
 'memusage/startup': 55136256,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 10, 55, 10, 169892)}
2020-04-16 03:55:12 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:55:58 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:55:58 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:55:58 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:55:58 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:55:58 [scrapy.extensions.telnet] INFO: Telnet Password: 038c31228c962233
2020-04-16 03:55:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 03:55:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:55:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:55:58 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-16 03:55:58 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:55:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:55:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:55:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:55:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  bug  Play store  app '
            'bugapp\xa0'
            'HackerOne '
            'issue1000app\xa0'
            'Dropbox, Duolingo, Line, Snapchat, Tinder, Alibaba, Mail.ru  '
            'Headspace '
            'appappappbughttps://www.engadget.com/2017/10/20/google-bug-bounty-program-android-apps/\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'WannaCryWannaCry150NSAWannaCryNSA(moderate '
            'confidence)WannaCryWannaCryNSAIPLazarus '
            'GroupWannaCry300cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t \xa0 \xa0 \xa0 \xa0'
            'GoogleUdacity75000AndroidGoogleUdacity20152016100010000Google '
            'EMEAMatt '
            'BrittinUdacity75000Google202050AndroidWebUdacity15000cnbetahttp://www.cnbeta.com/articles/tech/648715.htm\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  GMS '
            'OPPOvivoUnified '
            'Push '
            'ServiceUPSAPNS '
            'App  App '
            ' '
            'Android '
            'AppApp '
            'API  API '
            'AppSDKSDK '
            'ROM API '
            'SDKIT\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t splash '
            'screenappappAndroid '
            'Oreo\xa0Android 8.0\xa0\xa0splash screen '
            'APIAPIdrawableappActivityAndroid '
            'OreodrawableSplashActivityAPI\xa0'
            'Android Developers\xa0'
            '413AOSPAndroid '
            'O\xa0AOSP commit\xa0'
            'APIAndroid '
            'Oreo\xa0APIAndroid '
            'Open Source ProjectAndroid Oreo Adds a Splash Screen API so '
            'Developers can Easily Build App Loading Screens\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Google  Android 8.0 '
            'Oreo Android Beta Google  Oreo '
            'Google  Nexus  Pixel  '
            'Android 8.0 Google  '
            'EssentialHTCKyoceraMotorolaHMD '
            'GlobalNokia '
            'Android 8.0  2018  Pixel  '
            'HTC  LG  HTC  U11  Android '
            '8.0cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'AOL50Oath15%35%Altaba19952261322AOL50Oath15%35%AltabaAltaba6002300Verizon200015%1995 '
            'David FiloCEO2001Terry '
            'Semel10001.62Verizon748.344.82300300200020125Tumblr2300254%1553.12112%Terry '
            'SemelCarol '
            'BartzFacebookInstagramSnapchat199532100022SlackWhatsAppVerizon*************************************************************323Verizon55106.5150YahooMozillaAppFantasy2012iOSAndroid41400SSLHTML5HTTPS5201320142Mavens '
            'GAAP2042%20122102011GAAP1510BrightRollFlurry1720127451805303501028.6427%IPO1.22IPO908FYIPB&JHackdays48%25%17.5770Yaho-o-ooMarissahttp://netsmell.com/post/yahoo-45b-acquired-by.html\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t MinecraftXbox One '
            'X4K.jpgE3 '
            '2017MinecraftGears of War 4Forza '
            'Horizon 3Killer InstinctHalo Wars 24KSuper Duper '
            'Graphics...XD4K '
            '... 4K '
            'Better '
            'TogetherMinecraftMinecraftSuper '
            'Duper Graphics packXbox One '
            'X4KPCMinecraftMinecraftMinecraftSkinMinecraft\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            '517I/Ohttps://events.google.com/io/\xa0'
            'GoogleI/O Live '
            'Widget/517-19I/Oyoutubef '
            'q '
            'https://events.google.com/io/widget/?utm_source=google&utm_medium=social&utm_campaign=gplus\xa0'
            '\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t AndroidAndy '
            'RubinEssential PhoneEssential '
            'PhoneEssential '
            'PhoneEssential '
            'Phone8354GB128GB5.712560 x 1312 '
            'QHD19:103040mAh360UHD '
            '(3840x1920) 30Fps/DockEssential '
            'Phone1200 '
            '8004KEssential7.1.1ITEssential '
            'Phone3.5mmUSB-C5.069947893607495132 '
            'it\xa0http://mt.sohu.com/20170530/n495020791.shtml\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Java  James Gosling\xa0 AWS '
            'James Gosling  Facebook  '
            'Gosling  AWS '
            'Gosling  IoT  IoT '
            'James Gosling  Sun Microsystems  Java '
            ' Sun  '
            'Google Liquid Robotics  Wave '
            'GliderGosling '
            ' '
            '\xa0'
            '[http://www.oschina.net]https://www.oschina.net/news/85108/aws-signs-java-father-james-gosling\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Windows 10 SWindows '
            '10 Windows 10 SWindows RTWindows 10 '
            'SEdgeBingGoogle '
            'ChromeWindows StoreZDNetWindows '
            'StoreDekstop BridgeWindows '
            'StoreEdgeUWP '
            'EdgeHTMLJavaScriptWindows '
            'StoreWindows PlatformHTMLJavaScriptWindows '
            'StoreWindows '
            '10 '
            'ProiOSWebKitiOS '
            'ChromebookChromeGoogleChrome '
            'OSAndroidWindowsChromeFirefoxWindows '
            '10Windows 10 SChromebook '
            'EdgeChromeFirefoxcnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Fuchsia Git '
            ' UI Android  '
            'Chrome OS Fuchsia  Linux    '
            '"Magenta" FuchsiaLinux  GPL \xa0'
            'BSD 3 clause,\xa0MIT, \xa0Apache 2.0\xa0 Linux '
            ' Android  Linux  Google Pixel '
            ' 2014  Linux Kernel 3.18 \xa0Magenta '
            ' Fuchsia '
            ' Android '
            'Fuchsia '
            "\xa0Google's Flutter SDK\xa0"
            ' Android  iOS Flutter app  Dart '
            'Flutter SDK "Escher"\xa0Vulkan '
            ' shadow-heavy Material Design '
            'Fuchsia  UI  ArmadilloFuchsia  Flutter '
            'SDK Armadillo  Google  Fuchsia '
            ' UI  Android APK  Android  UI '
            '20% '
            'Fuchsia  Fuchsia IRC Fuchsia  Travis '
            'Geiselbrecht  20% '
            'Android '
            ' UI  '
            'Dart  Linux  GPL Java \xa0'
            'Oracle  Android  '
            'Android  Fuchsia  2020 '
            'Fuchsia '
            'arsTECHNICAhttp://www.oschina.net/news/84594/google-fuchsia-smartphone-os-dumps-linux-has-a-wild-new-ui\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'appAndroid '
            'batbatapphttps://green-android.org/app-convention.html\xa0'
            'AndroidAndroidAndroidAndroidAndroidAndroidGitHub '
            'issue trackerAndroidAndroid '
            'OAndroidTarget '
            'SDK Version >= 24 (Android 7.0)Project SvelteAndroid '
            '7READ_PHONE_STATEIMEIAndroid '
            '6.0Android\xa0'
            'SDKCPUIOCPUAlarmJobScheduler301CPUGoogleProject '
            'Volta121Android4.4 '
            '(Background-free)CPUIO '
            'Android O '
            '(Background-free)Android '
            'O3PendingIntentJobSchedulerAndroid '
            '5.0AndroidManifest.xmlAndroid '
            'OAndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xmlandroid.net.conn.CONNECTIVITY_CHANGE\xa0'
            'Android '
            '7android.hardware.action.NEW_PICTURE\xa0'
            'android.hardware.action.NEW_VIDEO\xa0'
            'android.net.wifi.SCAN_RESULTS\xa0 LocationManager '
            'android.intent.action.USER_PRESENT\xa0'
            'android.intent.action.ACTION_POWER_CONNECTED\xa0 '
            'JobScheduler '
            'android.intent.action.ACTION_POWER_DISCONNECTED\xa0 '
            'JobScheduler android.intent.action.MEDIA_\xa0'
            'AndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xml<receiver\xa0...\xa0'
            'android:enabled="@bool/until_api_21">/src/main/res/values/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">true</bool>\n'
            '</resources>/src/main/res/values-v21/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">false</bool>\n'
            '</resources>Android 4.4 / '
            'AndroidAndroid '
            '4.4Storage Access '
            'FrameworkAPITFUSB '
            'OTGNASDropboxGoogle '
            'Drive4.4AndroidAndroid '
            '4.4<uses-permission '
            'android:name="android.permission.WRITE_EXTERNAL_STORAGE" '
            'android:maxSdkVersion="18" '
            '/>Context.getExternalFilesDir()\xa0'
            'Context.getExternalCacheDir()\xa0APIAndroid '
            '4.4Android '
            '4.4Google '
            'PlayGoogle PlayGoogle '
            'PlayAndroidAndroidGoogle '
            'PlayAndroidGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'Play\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Android  Android '
            'Android  Google '
            'Android Google  4 Google  10  '
            'Google Pixel  Android Nought  7%  '
            'Android 7.1  0.5%2015  Android 6.0  2014  '
            'Android 5.0  31.2%  32 % Android N Android O '
            'googleGoogle  Android N '
            ' Android O '
            ' Android '
            ' Android O  Android '
            'Google Project\xa0Treble Google  '
            'Project Treble  Android  OEM '
            'Android  Google '
            ' Android '
            'Android O  '
            '9to5google Google  '
            'Android  QualcomMediatek LG '
            ' Android '
            ' '
            'Android  Google Google '
            ' Google Pixel  Nexus  cdnforo Project Treble  '
            'Android Google '
            'Vendor '
            'ImplementaTIonOEM '
            ' '
            'AndroidfonpitOEM '
            'Google  OEM  '
            'Android AOSPOEM  '
            'Android  OEM  AndroidAndroid O '
            'Google Project Treble Android O Android '
            'Google I/O 2017  5  18 '
            'ifanrandroidcommunityhttp://www.ifanr.com/835683\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:55:59 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:55:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 1.153355,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 55, 59, 991293),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/INFO': 10,
 'memusage/max': 55259136,
 'memusage/startup': 55259136,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 10, 55, 58, 837938)}
2020-04-16 03:55:59 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:58:08 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:58:08 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:58:08 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:58:08 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:58:08 [scrapy.extensions.telnet] INFO: Telnet Password: facfb96abb6f65d8
2020-04-16 03:58:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole']
2020-04-16 03:58:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:58:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:58:08 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-16 03:58:08 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:58:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:58:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:58:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:58:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Windows 10 SWindows '
            '10 Windows 10 SWindows RTWindows 10 '
            'SEdgeBingGoogle '
            'ChromeWindows StoreZDNetWindows '
            'StoreDekstop BridgeWindows '
            'StoreEdgeUWP '
            'EdgeHTMLJavaScriptWindows '
            'StoreWindows PlatformHTMLJavaScriptWindows '
            'StoreWindows '
            '10 '
            'ProiOSWebKitiOS '
            'ChromebookChromeGoogleChrome '
            'OSAndroidWindowsChromeFirefoxWindows '
            '10Windows 10 SChromebook '
            'EdgeChromeFirefoxcnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            '517I/Ohttps://events.google.com/io/\xa0'
            'GoogleI/O Live '
            'Widget/517-19I/Oyoutubef '
            'q '
            'https://events.google.com/io/widget/?utm_source=google&utm_medium=social&utm_campaign=gplus\xa0'
            '\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Fuchsia Git '
            ' UI Android  '
            'Chrome OS Fuchsia  Linux    '
            '"Magenta" FuchsiaLinux  GPL \xa0'
            'BSD 3 clause,\xa0MIT, \xa0Apache 2.0\xa0 Linux '
            ' Android  Linux  Google Pixel '
            ' 2014  Linux Kernel 3.18 \xa0Magenta '
            ' Fuchsia '
            ' Android '
            'Fuchsia '
            "\xa0Google's Flutter SDK\xa0"
            ' Android  iOS Flutter app  Dart '
            'Flutter SDK "Escher"\xa0Vulkan '
            ' shadow-heavy Material Design '
            'Fuchsia  UI  ArmadilloFuchsia  Flutter '
            'SDK Armadillo  Google  Fuchsia '
            ' UI  Android APK  Android  UI '
            '20% '
            'Fuchsia  Fuchsia IRC Fuchsia  Travis '
            'Geiselbrecht  20% '
            'Android '
            ' UI  '
            'Dart  Linux  GPL Java \xa0'
            'Oracle  Android  '
            'Android  Fuchsia  2020 '
            'Fuchsia '
            'arsTECHNICAhttp://www.oschina.net/news/84594/google-fuchsia-smartphone-os-dumps-linux-has-a-wild-new-ui\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t MinecraftXbox One '
            'X4K.jpgE3 '
            '2017MinecraftGears of War 4Forza '
            'Horizon 3Killer InstinctHalo Wars 24KSuper Duper '
            'Graphics...XD4K '
            '... 4K '
            'Better '
            'TogetherMinecraftMinecraftSuper '
            'Duper Graphics packXbox One '
            'X4KPCMinecraftMinecraftMinecraftSkinMinecraft\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Google  Android 8.0 '
            'Oreo Android Beta Google  Oreo '
            'Google  Nexus  Pixel  '
            'Android 8.0 Google  '
            'EssentialHTCKyoceraMotorolaHMD '
            'GlobalNokia '
            'Android 8.0  2018  Pixel  '
            'HTC  LG  HTC  U11  Android '
            '8.0cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t splash '
            'screenappappAndroid '
            'Oreo\xa0Android 8.0\xa0\xa0splash screen '
            'APIAPIdrawableappActivityAndroid '
            'OreodrawableSplashActivityAPI\xa0'
            'Android Developers\xa0'
            '413AOSPAndroid '
            'O\xa0AOSP commit\xa0'
            'APIAndroid '
            'Oreo\xa0APIAndroid '
            'Open Source ProjectAndroid Oreo Adds a Splash Screen API so '
            'Developers can Easily Build App Loading Screens\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  bug  Play store  app '
            'bugapp\xa0'
            'HackerOne '
            'issue1000app\xa0'
            'Dropbox, Duolingo, Line, Snapchat, Tinder, Alibaba, Mail.ru  '
            'Headspace '
            'appappappbughttps://www.engadget.com/2017/10/20/google-bug-bounty-program-android-apps/\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t \xa0 \xa0 \xa0 \xa0'
            'GoogleUdacity75000AndroidGoogleUdacity20152016100010000Google '
            'EMEAMatt '
            'BrittinUdacity75000Google202050AndroidWebUdacity15000cnbetahttp://www.cnbeta.com/articles/tech/648715.htm\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Android  Android '
            'Android  Google '
            'Android Google  4 Google  10  '
            'Google Pixel  Android Nought  7%  '
            'Android 7.1  0.5%2015  Android 6.0  2014  '
            'Android 5.0  31.2%  32 % Android N Android O '
            'googleGoogle  Android N '
            ' Android O '
            ' Android '
            ' Android O  Android '
            'Google Project\xa0Treble Google  '
            'Project Treble  Android  OEM '
            'Android  Google '
            ' Android '
            'Android O  '
            '9to5google Google  '
            'Android  QualcomMediatek LG '
            ' Android '
            ' '
            'Android  Google Google '
            ' Google Pixel  Nexus  cdnforo Project Treble  '
            'Android Google '
            'Vendor '
            'ImplementaTIonOEM '
            ' '
            'AndroidfonpitOEM '
            'Google  OEM  '
            'Android AOSPOEM  '
            'Android  OEM  AndroidAndroid O '
            'Google Project Treble Android O Android '
            'Google I/O 2017  5  18 '
            'ifanrandroidcommunityhttp://www.ifanr.com/835683\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Java  James Gosling\xa0 AWS '
            'James Gosling  Facebook  '
            'Gosling  AWS '
            'Gosling  IoT  IoT '
            'James Gosling  Sun Microsystems  Java '
            ' Sun  '
            'Google Liquid Robotics  Wave '
            'GliderGosling '
            ' '
            '\xa0'
            '[http://www.oschina.net]https://www.oschina.net/news/85108/aws-signs-java-father-james-gosling\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'appAndroid '
            'batbatapphttps://green-android.org/app-convention.html\xa0'
            'AndroidAndroidAndroidAndroidAndroidAndroidGitHub '
            'issue trackerAndroidAndroid '
            'OAndroidTarget '
            'SDK Version >= 24 (Android 7.0)Project SvelteAndroid '
            '7READ_PHONE_STATEIMEIAndroid '
            '6.0Android\xa0'
            'SDKCPUIOCPUAlarmJobScheduler301CPUGoogleProject '
            'Volta121Android4.4 '
            '(Background-free)CPUIO '
            'Android O '
            '(Background-free)Android '
            'O3PendingIntentJobSchedulerAndroid '
            '5.0AndroidManifest.xmlAndroid '
            'OAndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xmlandroid.net.conn.CONNECTIVITY_CHANGE\xa0'
            'Android '
            '7android.hardware.action.NEW_PICTURE\xa0'
            'android.hardware.action.NEW_VIDEO\xa0'
            'android.net.wifi.SCAN_RESULTS\xa0 LocationManager '
            'android.intent.action.USER_PRESENT\xa0'
            'android.intent.action.ACTION_POWER_CONNECTED\xa0 '
            'JobScheduler '
            'android.intent.action.ACTION_POWER_DISCONNECTED\xa0 '
            'JobScheduler android.intent.action.MEDIA_\xa0'
            'AndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xml<receiver\xa0...\xa0'
            'android:enabled="@bool/until_api_21">/src/main/res/values/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">true</bool>\n'
            '</resources>/src/main/res/values-v21/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">false</bool>\n'
            '</resources>Android 4.4 / '
            'AndroidAndroid '
            '4.4Storage Access '
            'FrameworkAPITFUSB '
            'OTGNASDropboxGoogle '
            'Drive4.4AndroidAndroid '
            '4.4<uses-permission '
            'android:name="android.permission.WRITE_EXTERNAL_STORAGE" '
            'android:maxSdkVersion="18" '
            '/>Context.getExternalFilesDir()\xa0'
            'Context.getExternalCacheDir()\xa0APIAndroid '
            '4.4Android '
            '4.4Google '
            'PlayGoogle PlayGoogle '
            'PlayAndroidAndroidGoogle '
            'PlayAndroidGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'Play\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'WannaCryWannaCry150NSAWannaCryNSA(moderate '
            'confidence)WannaCryWannaCryNSAIPLazarus '
            'GroupWannaCry300cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'AOL50Oath15%35%Altaba19952261322AOL50Oath15%35%AltabaAltaba6002300Verizon200015%1995 '
            'David FiloCEO2001Terry '
            'Semel10001.62Verizon748.344.82300300200020125Tumblr2300254%1553.12112%Terry '
            'SemelCarol '
            'BartzFacebookInstagramSnapchat199532100022SlackWhatsAppVerizon*************************************************************323Verizon55106.5150YahooMozillaAppFantasy2012iOSAndroid41400SSLHTML5HTTPS5201320142Mavens '
            'GAAP2042%20122102011GAAP1510BrightRollFlurry1720127451805303501028.6427%IPO1.22IPO908FYIPB&JHackdays48%25%17.5770Yaho-o-ooMarissahttp://netsmell.com/post/yahoo-45b-acquired-by.html\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  GMS '
            'OPPOvivoUnified '
            'Push '
            'ServiceUPSAPNS '
            'App  App '
            ' '
            'Android '
            'AppApp '
            'API  API '
            'AppSDKSDK '
            'ROM API '
            'SDKIT\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t AndroidAndy '
            'RubinEssential PhoneEssential '
            'PhoneEssential '
            'PhoneEssential '
            'Phone8354GB128GB5.712560 x 1312 '
            'QHD19:103040mAh360UHD '
            '(3840x1920) 30Fps/DockEssential '
            'Phone1200 '
            '8004KEssential7.1.1ITEssential '
            'Phone3.5mmUSB-C5.069947893607495132 '
            'it\xa0http://mt.sohu.com/20170530/n495020791.shtml\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:09 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:58:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 0.750133,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 58, 9, 564156),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/INFO': 10,
 'memusage/max': 54034432,
 'memusage/startup': 54034432,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 10, 58, 8, 814023)}
2020-04-16 03:58:09 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:58:22 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:58:22 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:58:22 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:58:22 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:58:22 [scrapy.extensions.telnet] INFO: Telnet Password: c3a60834c25610f1
2020-04-16 03:58:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2020-04-16 03:58:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:58:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:58:22 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-16 03:58:22 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:58:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:58:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:58:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'WannaCryWannaCry150NSAWannaCryNSA(moderate '
            'confidence)WannaCryWannaCryNSAIPLazarus '
            'GroupWannaCry300cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t AndroidAndy '
            'RubinEssential PhoneEssential '
            'PhoneEssential '
            'PhoneEssential '
            'Phone8354GB128GB5.712560 x 1312 '
            'QHD19:103040mAh360UHD '
            '(3840x1920) 30Fps/DockEssential '
            'Phone1200 '
            '8004KEssential7.1.1ITEssential '
            'Phone3.5mmUSB-C5.069947893607495132 '
            'it\xa0http://mt.sohu.com/20170530/n495020791.shtml\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Java  James Gosling\xa0 AWS '
            'James Gosling  Facebook  '
            'Gosling  AWS '
            'Gosling  IoT  IoT '
            'James Gosling  Sun Microsystems  Java '
            ' Sun  '
            'Google Liquid Robotics  Wave '
            'GliderGosling '
            ' '
            '\xa0'
            '[http://www.oschina.net]https://www.oschina.net/news/85108/aws-signs-java-father-james-gosling\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  GMS '
            'OPPOvivoUnified '
            'Push '
            'ServiceUPSAPNS '
            'App  App '
            ' '
            'Android '
            'AppApp '
            'API  API '
            'AppSDKSDK '
            'ROM API '
            'SDKIT\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'appAndroid '
            'batbatapphttps://green-android.org/app-convention.html\xa0'
            'AndroidAndroidAndroidAndroidAndroidAndroidGitHub '
            'issue trackerAndroidAndroid '
            'OAndroidTarget '
            'SDK Version >= 24 (Android 7.0)Project SvelteAndroid '
            '7READ_PHONE_STATEIMEIAndroid '
            '6.0Android\xa0'
            'SDKCPUIOCPUAlarmJobScheduler301CPUGoogleProject '
            'Volta121Android4.4 '
            '(Background-free)CPUIO '
            'Android O '
            '(Background-free)Android '
            'O3PendingIntentJobSchedulerAndroid '
            '5.0AndroidManifest.xmlAndroid '
            'OAndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xmlandroid.net.conn.CONNECTIVITY_CHANGE\xa0'
            'Android '
            '7android.hardware.action.NEW_PICTURE\xa0'
            'android.hardware.action.NEW_VIDEO\xa0'
            'android.net.wifi.SCAN_RESULTS\xa0 LocationManager '
            'android.intent.action.USER_PRESENT\xa0'
            'android.intent.action.ACTION_POWER_CONNECTED\xa0 '
            'JobScheduler '
            'android.intent.action.ACTION_POWER_DISCONNECTED\xa0 '
            'JobScheduler android.intent.action.MEDIA_\xa0'
            'AndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xml<receiver\xa0...\xa0'
            'android:enabled="@bool/until_api_21">/src/main/res/values/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">true</bool>\n'
            '</resources>/src/main/res/values-v21/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">false</bool>\n'
            '</resources>Android 4.4 / '
            'AndroidAndroid '
            '4.4Storage Access '
            'FrameworkAPITFUSB '
            'OTGNASDropboxGoogle '
            'Drive4.4AndroidAndroid '
            '4.4<uses-permission '
            'android:name="android.permission.WRITE_EXTERNAL_STORAGE" '
            'android:maxSdkVersion="18" '
            '/>Context.getExternalFilesDir()\xa0'
            'Context.getExternalCacheDir()\xa0APIAndroid '
            '4.4Android '
            '4.4Google '
            'PlayGoogle PlayGoogle '
            'PlayAndroidAndroidGoogle '
            'PlayAndroidGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'Play\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Android  Android '
            'Android  Google '
            'Android Google  4 Google  10  '
            'Google Pixel  Android Nought  7%  '
            'Android 7.1  0.5%2015  Android 6.0  2014  '
            'Android 5.0  31.2%  32 % Android N Android O '
            'googleGoogle  Android N '
            ' Android O '
            ' Android '
            ' Android O  Android '
            'Google Project\xa0Treble Google  '
            'Project Treble  Android  OEM '
            'Android  Google '
            ' Android '
            'Android O  '
            '9to5google Google  '
            'Android  QualcomMediatek LG '
            ' Android '
            ' '
            'Android  Google Google '
            ' Google Pixel  Nexus  cdnforo Project Treble  '
            'Android Google '
            'Vendor '
            'ImplementaTIonOEM '
            ' '
            'AndroidfonpitOEM '
            'Google  OEM  '
            'Android AOSPOEM  '
            'Android  OEM  AndroidAndroid O '
            'Google Project Treble Android O Android '
            'Google I/O 2017  5  18 '
            'ifanrandroidcommunityhttp://www.ifanr.com/835683\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'AOL50Oath15%35%Altaba19952261322AOL50Oath15%35%AltabaAltaba6002300Verizon200015%1995 '
            'David FiloCEO2001Terry '
            'Semel10001.62Verizon748.344.82300300200020125Tumblr2300254%1553.12112%Terry '
            'SemelCarol '
            'BartzFacebookInstagramSnapchat199532100022SlackWhatsAppVerizon*************************************************************323Verizon55106.5150YahooMozillaAppFantasy2012iOSAndroid41400SSLHTML5HTTPS5201320142Mavens '
            'GAAP2042%20122102011GAAP1510BrightRollFlurry1720127451805303501028.6427%IPO1.22IPO908FYIPB&JHackdays48%25%17.5770Yaho-o-ooMarissahttp://netsmell.com/post/yahoo-45b-acquired-by.html\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Windows 10 SWindows '
            '10 Windows 10 SWindows RTWindows 10 '
            'SEdgeBingGoogle '
            'ChromeWindows StoreZDNetWindows '
            'StoreDekstop BridgeWindows '
            'StoreEdgeUWP '
            'EdgeHTMLJavaScriptWindows '
            'StoreWindows PlatformHTMLJavaScriptWindows '
            'StoreWindows '
            '10 '
            'ProiOSWebKitiOS '
            'ChromebookChromeGoogleChrome '
            'OSAndroidWindowsChromeFirefoxWindows '
            '10Windows 10 SChromebook '
            'EdgeChromeFirefoxcnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t MinecraftXbox One '
            'X4K.jpgE3 '
            '2017MinecraftGears of War 4Forza '
            'Horizon 3Killer InstinctHalo Wars 24KSuper Duper '
            'Graphics...XD4K '
            '... 4K '
            'Better '
            'TogetherMinecraftMinecraftSuper '
            'Duper Graphics packXbox One '
            'X4KPCMinecraftMinecraftMinecraftSkinMinecraft\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Google  Android 8.0 '
            'Oreo Android Beta Google  Oreo '
            'Google  Nexus  Pixel  '
            'Android 8.0 Google  '
            'EssentialHTCKyoceraMotorolaHMD '
            'GlobalNokia '
            'Android 8.0  2018  Pixel  '
            'HTC  LG  HTC  U11  Android '
            '8.0cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  bug  Play store  app '
            'bugapp\xa0'
            'HackerOne '
            'issue1000app\xa0'
            'Dropbox, Duolingo, Line, Snapchat, Tinder, Alibaba, Mail.ru  '
            'Headspace '
            'appappappbughttps://www.engadget.com/2017/10/20/google-bug-bounty-program-android-apps/\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t \xa0 \xa0 \xa0 \xa0'
            'GoogleUdacity75000AndroidGoogleUdacity20152016100010000Google '
            'EMEAMatt '
            'BrittinUdacity75000Google202050AndroidWebUdacity15000cnbetahttp://www.cnbeta.com/articles/tech/648715.htm\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t splash '
            'screenappappAndroid '
            'Oreo\xa0Android 8.0\xa0\xa0splash screen '
            'APIAPIdrawableappActivityAndroid '
            'OreodrawableSplashActivityAPI\xa0'
            'Android Developers\xa0'
            '413AOSPAndroid '
            'O\xa0AOSP commit\xa0'
            'APIAndroid '
            'Oreo\xa0APIAndroid '
            'Open Source ProjectAndroid Oreo Adds a Splash Screen API so '
            'Developers can Easily Build App Loading Screens\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            '517I/Ohttps://events.google.com/io/\xa0'
            'GoogleI/O Live '
            'Widget/517-19I/Oyoutubef '
            'q '
            'https://events.google.com/io/widget/?utm_source=google&utm_medium=social&utm_campaign=gplus\xa0'
            '\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Fuchsia Git '
            ' UI Android  '
            'Chrome OS Fuchsia  Linux    '
            '"Magenta" FuchsiaLinux  GPL \xa0'
            'BSD 3 clause,\xa0MIT, \xa0Apache 2.0\xa0 Linux '
            ' Android  Linux  Google Pixel '
            ' 2014  Linux Kernel 3.18 \xa0Magenta '
            ' Fuchsia '
            ' Android '
            'Fuchsia '
            "\xa0Google's Flutter SDK\xa0"
            ' Android  iOS Flutter app  Dart '
            'Flutter SDK "Escher"\xa0Vulkan '
            ' shadow-heavy Material Design '
            'Fuchsia  UI  ArmadilloFuchsia  Flutter '
            'SDK Armadillo  Google  Fuchsia '
            ' UI  Android APK  Android  UI '
            '20% '
            'Fuchsia  Fuchsia IRC Fuchsia  Travis '
            'Geiselbrecht  20% '
            'Android '
            ' UI  '
            'Dart  Linux  GPL Java \xa0'
            'Oracle  Android  '
            'Android  Fuchsia  2020 '
            'Fuchsia '
            'arsTECHNICAhttp://www.oschina.net/news/84594/google-fuchsia-smartphone-os-dumps-linux-has-a-wild-new-ui\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:23 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:58:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 0.750804,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 58, 23, 575424),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/INFO': 10,
 'memusage/max': 53932032,
 'memusage/startup': 53932032,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 10, 58, 22, 824620)}
2020-04-16 03:58:23 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:58:50 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:58:50 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:58:50 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:58:50 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:58:50 [scrapy.extensions.telnet] INFO: Telnet Password: 8fd99d5fc67d2170
2020-04-16 03:58:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 03:58:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:58:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:58:50 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-16 03:58:50 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:58:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:58:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Fuchsia Git '
            ' UI Android  '
            'Chrome OS Fuchsia  Linux    '
            '"Magenta" FuchsiaLinux  GPL \xa0'
            'BSD 3 clause,\xa0MIT, \xa0Apache 2.0\xa0 Linux '
            ' Android  Linux  Google Pixel '
            ' 2014  Linux Kernel 3.18 \xa0Magenta '
            ' Fuchsia '
            ' Android '
            'Fuchsia '
            "\xa0Google's Flutter SDK\xa0"
            ' Android  iOS Flutter app  Dart '
            'Flutter SDK "Escher"\xa0Vulkan '
            ' shadow-heavy Material Design '
            'Fuchsia  UI  ArmadilloFuchsia  Flutter '
            'SDK Armadillo  Google  Fuchsia '
            ' UI  Android APK  Android  UI '
            '20% '
            'Fuchsia  Fuchsia IRC Fuchsia  Travis '
            'Geiselbrecht  20% '
            'Android '
            ' UI  '
            'Dart  Linux  GPL Java \xa0'
            'Oracle  Android  '
            'Android  Fuchsia  2020 '
            'Fuchsia '
            'arsTECHNICAhttp://www.oschina.net/news/84594/google-fuchsia-smartphone-os-dumps-linux-has-a-wild-new-ui\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t AndroidAndy '
            'RubinEssential PhoneEssential '
            'PhoneEssential '
            'PhoneEssential '
            'Phone8354GB128GB5.712560 x 1312 '
            'QHD19:103040mAh360UHD '
            '(3840x1920) 30Fps/DockEssential '
            'Phone1200 '
            '8004KEssential7.1.1ITEssential '
            'Phone3.5mmUSB-C5.069947893607495132 '
            'it\xa0http://mt.sohu.com/20170530/n495020791.shtml\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'appAndroid '
            'batbatapphttps://green-android.org/app-convention.html\xa0'
            'AndroidAndroidAndroidAndroidAndroidAndroidGitHub '
            'issue trackerAndroidAndroid '
            'OAndroidTarget '
            'SDK Version >= 24 (Android 7.0)Project SvelteAndroid '
            '7READ_PHONE_STATEIMEIAndroid '
            '6.0Android\xa0'
            'SDKCPUIOCPUAlarmJobScheduler301CPUGoogleProject '
            'Volta121Android4.4 '
            '(Background-free)CPUIO '
            'Android O '
            '(Background-free)Android '
            'O3PendingIntentJobSchedulerAndroid '
            '5.0AndroidManifest.xmlAndroid '
            'OAndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xmlandroid.net.conn.CONNECTIVITY_CHANGE\xa0'
            'Android '
            '7android.hardware.action.NEW_PICTURE\xa0'
            'android.hardware.action.NEW_VIDEO\xa0'
            'android.net.wifi.SCAN_RESULTS\xa0 LocationManager '
            'android.intent.action.USER_PRESENT\xa0'
            'android.intent.action.ACTION_POWER_CONNECTED\xa0 '
            'JobScheduler '
            'android.intent.action.ACTION_POWER_DISCONNECTED\xa0 '
            'JobScheduler android.intent.action.MEDIA_\xa0'
            'AndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xml<receiver\xa0...\xa0'
            'android:enabled="@bool/until_api_21">/src/main/res/values/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">true</bool>\n'
            '</resources>/src/main/res/values-v21/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">false</bool>\n'
            '</resources>Android 4.4 / '
            'AndroidAndroid '
            '4.4Storage Access '
            'FrameworkAPITFUSB '
            'OTGNASDropboxGoogle '
            'Drive4.4AndroidAndroid '
            '4.4<uses-permission '
            'android:name="android.permission.WRITE_EXTERNAL_STORAGE" '
            'android:maxSdkVersion="18" '
            '/>Context.getExternalFilesDir()\xa0'
            'Context.getExternalCacheDir()\xa0APIAndroid '
            '4.4Android '
            '4.4Google '
            'PlayGoogle PlayGoogle '
            'PlayAndroidAndroidGoogle '
            'PlayAndroidGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'Play\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            '517I/Ohttps://events.google.com/io/\xa0'
            'GoogleI/O Live '
            'Widget/517-19I/Oyoutubef '
            'q '
            'https://events.google.com/io/widget/?utm_source=google&utm_medium=social&utm_campaign=gplus\xa0'
            '\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Android  Android '
            'Android  Google '
            'Android Google  4 Google  10  '
            'Google Pixel  Android Nought  7%  '
            'Android 7.1  0.5%2015  Android 6.0  2014  '
            'Android 5.0  31.2%  32 % Android N Android O '
            'googleGoogle  Android N '
            ' Android O '
            ' Android '
            ' Android O  Android '
            'Google Project\xa0Treble Google  '
            'Project Treble  Android  OEM '
            'Android  Google '
            ' Android '
            'Android O  '
            '9to5google Google  '
            'Android  QualcomMediatek LG '
            ' Android '
            ' '
            'Android  Google Google '
            ' Google Pixel  Nexus  cdnforo Project Treble  '
            'Android Google '
            'Vendor '
            'ImplementaTIonOEM '
            ' '
            'AndroidfonpitOEM '
            'Google  OEM  '
            'Android AOSPOEM  '
            'Android  OEM  AndroidAndroid O '
            'Google Project Treble Android O Android '
            'Google I/O 2017  5  18 '
            'ifanrandroidcommunityhttp://www.ifanr.com/835683\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Windows 10 SWindows '
            '10 Windows 10 SWindows RTWindows 10 '
            'SEdgeBingGoogle '
            'ChromeWindows StoreZDNetWindows '
            'StoreDekstop BridgeWindows '
            'StoreEdgeUWP '
            'EdgeHTMLJavaScriptWindows '
            'StoreWindows PlatformHTMLJavaScriptWindows '
            'StoreWindows '
            '10 '
            'ProiOSWebKitiOS '
            'ChromebookChromeGoogleChrome '
            'OSAndroidWindowsChromeFirefoxWindows '
            '10Windows 10 SChromebook '
            'EdgeChromeFirefoxcnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Java  James Gosling\xa0 AWS '
            'James Gosling  Facebook  '
            'Gosling  AWS '
            'Gosling  IoT  IoT '
            'James Gosling  Sun Microsystems  Java '
            ' Sun  '
            'Google Liquid Robotics  Wave '
            'GliderGosling '
            ' '
            '\xa0'
            '[http://www.oschina.net]https://www.oschina.net/news/85108/aws-signs-java-father-james-gosling\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  GMS '
            'OPPOvivoUnified '
            'Push '
            'ServiceUPSAPNS '
            'App  App '
            ' '
            'Android '
            'AppApp '
            'API  API '
            'AppSDKSDK '
            'ROM API '
            'SDKIT\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'WannaCryWannaCry150NSAWannaCryNSA(moderate '
            'confidence)WannaCryWannaCryNSAIPLazarus '
            'GroupWannaCry300cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t MinecraftXbox One '
            'X4K.jpgE3 '
            '2017MinecraftGears of War 4Forza '
            'Horizon 3Killer InstinctHalo Wars 24KSuper Duper '
            'Graphics...XD4K '
            '... 4K '
            'Better '
            'TogetherMinecraftMinecraftSuper '
            'Duper Graphics packXbox One '
            'X4KPCMinecraftMinecraftMinecraftSkinMinecraft\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'AOL50Oath15%35%Altaba19952261322AOL50Oath15%35%AltabaAltaba6002300Verizon200015%1995 '
            'David FiloCEO2001Terry '
            'Semel10001.62Verizon748.344.82300300200020125Tumblr2300254%1553.12112%Terry '
            'SemelCarol '
            'BartzFacebookInstagramSnapchat199532100022SlackWhatsAppVerizon*************************************************************323Verizon55106.5150YahooMozillaAppFantasy2012iOSAndroid41400SSLHTML5HTTPS5201320142Mavens '
            'GAAP2042%20122102011GAAP1510BrightRollFlurry1720127451805303501028.6427%IPO1.22IPO908FYIPB&JHackdays48%25%17.5770Yaho-o-ooMarissahttp://netsmell.com/post/yahoo-45b-acquired-by.html\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t splash '
            'screenappappAndroid '
            'Oreo\xa0Android 8.0\xa0\xa0splash screen '
            'APIAPIdrawableappActivityAndroid '
            'OreodrawableSplashActivityAPI\xa0'
            'Android Developers\xa0'
            '413AOSPAndroid '
            'O\xa0AOSP commit\xa0'
            'APIAndroid '
            'Oreo\xa0APIAndroid '
            'Open Source ProjectAndroid Oreo Adds a Splash Screen API so '
            'Developers can Easily Build App Loading Screens\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  bug  Play store  app '
            'bugapp\xa0'
            'HackerOne '
            'issue1000app\xa0'
            'Dropbox, Duolingo, Line, Snapchat, Tinder, Alibaba, Mail.ru  '
            'Headspace '
            'appappappbughttps://www.engadget.com/2017/10/20/google-bug-bounty-program-android-apps/\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Google  Android 8.0 '
            'Oreo Android Beta Google  Oreo '
            'Google  Nexus  Pixel  '
            'Android 8.0 Google  '
            'EssentialHTCKyoceraMotorolaHMD '
            'GlobalNokia '
            'Android 8.0  2018  Pixel  '
            'HTC  LG  HTC  U11  Android '
            '8.0cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t \xa0 \xa0 \xa0 \xa0'
            'GoogleUdacity75000AndroidGoogleUdacity20152016100010000Google '
            'EMEAMatt '
            'BrittinUdacity75000Google202050AndroidWebUdacity15000cnbetahttp://www.cnbeta.com/articles/tech/648715.htm\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:58:51 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:58:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 0.695266,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 58, 51, 652264),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/INFO': 10,
 'memusage/max': 54292480,
 'memusage/startup': 54292480,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 10, 58, 50, 956998)}
2020-04-16 03:58:51 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 03:59:19 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 03:59:19 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 03:59:19 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 03:59:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 03:59:19 [scrapy.extensions.telnet] INFO: Telnet Password: 197353b78202f7d0
2020-04-16 03:59:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-04-16 03:59:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 03:59:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 03:59:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 03:59:19 [scrapy.core.engine] INFO: Spider opened
2020-04-16 03:59:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 03:59:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 03:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 03:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Android  Android '
            'Android  Google '
            'Android Google  4 Google  10  '
            'Google Pixel  Android Nought  7%  '
            'Android 7.1  0.5%2015  Android 6.0  2014  '
            'Android 5.0  31.2%  32 % Android N Android O '
            'googleGoogle  Android N '
            ' Android O '
            ' Android '
            ' Android O  Android '
            'Google Project\xa0Treble Google  '
            'Project Treble  Android  OEM '
            'Android  Google '
            ' Android '
            'Android O  '
            '9to5google Google  '
            'Android  QualcomMediatek LG '
            ' Android '
            ' '
            'Android  Google Google '
            ' Google Pixel  Nexus  cdnforo Project Treble  '
            'Android Google '
            'Vendor '
            'ImplementaTIonOEM '
            ' '
            'AndroidfonpitOEM '
            'Google  OEM  '
            'Android AOSPOEM  '
            'Android  OEM  AndroidAndroid O '
            'Google Project Treble Android O Android '
            'Google I/O 2017  5  18 '
            'ifanrandroidcommunityhttp://www.ifanr.com/835683\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Windows 10 SWindows '
            '10 Windows 10 SWindows RTWindows 10 '
            'SEdgeBingGoogle '
            'ChromeWindows StoreZDNetWindows '
            'StoreDekstop BridgeWindows '
            'StoreEdgeUWP '
            'EdgeHTMLJavaScriptWindows '
            'StoreWindows PlatformHTMLJavaScriptWindows '
            'StoreWindows '
            '10 '
            'ProiOSWebKitiOS '
            'ChromebookChromeGoogleChrome '
            'OSAndroidWindowsChromeFirefoxWindows '
            '10Windows 10 SChromebook '
            'EdgeChromeFirefoxcnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  GMS '
            'OPPOvivoUnified '
            'Push '
            'ServiceUPSAPNS '
            'App  App '
            ' '
            'Android '
            'AppApp '
            'API  API '
            'AppSDKSDK '
            'ROM API '
            'SDKIT\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'appAndroid '
            'batbatapphttps://green-android.org/app-convention.html\xa0'
            'AndroidAndroidAndroidAndroidAndroidAndroidGitHub '
            'issue trackerAndroidAndroid '
            'OAndroidTarget '
            'SDK Version >= 24 (Android 7.0)Project SvelteAndroid '
            '7READ_PHONE_STATEIMEIAndroid '
            '6.0Android\xa0'
            'SDKCPUIOCPUAlarmJobScheduler301CPUGoogleProject '
            'Volta121Android4.4 '
            '(Background-free)CPUIO '
            'Android O '
            '(Background-free)Android '
            'O3PendingIntentJobSchedulerAndroid '
            '5.0AndroidManifest.xmlAndroid '
            'OAndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xmlandroid.net.conn.CONNECTIVITY_CHANGE\xa0'
            'Android '
            '7android.hardware.action.NEW_PICTURE\xa0'
            'android.hardware.action.NEW_VIDEO\xa0'
            'android.net.wifi.SCAN_RESULTS\xa0 LocationManager '
            'android.intent.action.USER_PRESENT\xa0'
            'android.intent.action.ACTION_POWER_CONNECTED\xa0 '
            'JobScheduler '
            'android.intent.action.ACTION_POWER_DISCONNECTED\xa0 '
            'JobScheduler android.intent.action.MEDIA_\xa0'
            'AndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xml<receiver\xa0...\xa0'
            'android:enabled="@bool/until_api_21">/src/main/res/values/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">true</bool>\n'
            '</resources>/src/main/res/values-v21/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">false</bool>\n'
            '</resources>Android 4.4 / '
            'AndroidAndroid '
            '4.4Storage Access '
            'FrameworkAPITFUSB '
            'OTGNASDropboxGoogle '
            'Drive4.4AndroidAndroid '
            '4.4<uses-permission '
            'android:name="android.permission.WRITE_EXTERNAL_STORAGE" '
            'android:maxSdkVersion="18" '
            '/>Context.getExternalFilesDir()\xa0'
            'Context.getExternalCacheDir()\xa0APIAndroid '
            '4.4Android '
            '4.4Google '
            'PlayGoogle PlayGoogle '
            'PlayAndroidAndroidGoogle '
            'PlayAndroidGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'Play\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Fuchsia Git '
            ' UI Android  '
            'Chrome OS Fuchsia  Linux    '
            '"Magenta" FuchsiaLinux  GPL \xa0'
            'BSD 3 clause,\xa0MIT, \xa0Apache 2.0\xa0 Linux '
            ' Android  Linux  Google Pixel '
            ' 2014  Linux Kernel 3.18 \xa0Magenta '
            ' Fuchsia '
            ' Android '
            'Fuchsia '
            "\xa0Google's Flutter SDK\xa0"
            ' Android  iOS Flutter app  Dart '
            'Flutter SDK "Escher"\xa0Vulkan '
            ' shadow-heavy Material Design '
            'Fuchsia  UI  ArmadilloFuchsia  Flutter '
            'SDK Armadillo  Google  Fuchsia '
            ' UI  Android APK  Android  UI '
            '20% '
            'Fuchsia  Fuchsia IRC Fuchsia  Travis '
            'Geiselbrecht  20% '
            'Android '
            ' UI  '
            'Dart  Linux  GPL Java \xa0'
            'Oracle  Android  '
            'Android  Fuchsia  2020 '
            'Fuchsia '
            'arsTECHNICAhttp://www.oschina.net/news/84594/google-fuchsia-smartphone-os-dumps-linux-has-a-wild-new-ui\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t AndroidAndy '
            'RubinEssential PhoneEssential '
            'PhoneEssential '
            'PhoneEssential '
            'Phone8354GB128GB5.712560 x 1312 '
            'QHD19:103040mAh360UHD '
            '(3840x1920) 30Fps/DockEssential '
            'Phone1200 '
            '8004KEssential7.1.1ITEssential '
            'Phone3.5mmUSB-C5.069947893607495132 '
            'it\xa0http://mt.sohu.com/20170530/n495020791.shtml\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'WannaCryWannaCry150NSAWannaCryNSA(moderate '
            'confidence)WannaCryWannaCryNSAIPLazarus '
            'GroupWannaCry300cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Java  James Gosling\xa0 AWS '
            'James Gosling  Facebook  '
            'Gosling  AWS '
            'Gosling  IoT  IoT '
            'James Gosling  Sun Microsystems  Java '
            ' Sun  '
            'Google Liquid Robotics  Wave '
            'GliderGosling '
            ' '
            '\xa0'
            '[http://www.oschina.net]https://www.oschina.net/news/85108/aws-signs-java-father-james-gosling\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'AOL50Oath15%35%Altaba19952261322AOL50Oath15%35%AltabaAltaba6002300Verizon200015%1995 '
            'David FiloCEO2001Terry '
            'Semel10001.62Verizon748.344.82300300200020125Tumblr2300254%1553.12112%Terry '
            'SemelCarol '
            'BartzFacebookInstagramSnapchat199532100022SlackWhatsAppVerizon*************************************************************323Verizon55106.5150YahooMozillaAppFantasy2012iOSAndroid41400SSLHTML5HTTPS5201320142Mavens '
            'GAAP2042%20122102011GAAP1510BrightRollFlurry1720127451805303501028.6427%IPO1.22IPO908FYIPB&JHackdays48%25%17.5770Yaho-o-ooMarissahttp://netsmell.com/post/yahoo-45b-acquired-by.html\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Google  Android 8.0 '
            'Oreo Android Beta Google  Oreo '
            'Google  Nexus  Pixel  '
            'Android 8.0 Google  '
            'EssentialHTCKyoceraMotorolaHMD '
            'GlobalNokia '
            'Android 8.0  2018  Pixel  '
            'HTC  LG  HTC  U11  Android '
            '8.0cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t \xa0 \xa0 \xa0 \xa0'
            'GoogleUdacity75000AndroidGoogleUdacity20152016100010000Google '
            'EMEAMatt '
            'BrittinUdacity75000Google202050AndroidWebUdacity15000cnbetahttp://www.cnbeta.com/articles/tech/648715.htm\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  bug  Play store  app '
            'bugapp\xa0'
            'HackerOne '
            'issue1000app\xa0'
            'Dropbox, Duolingo, Line, Snapchat, Tinder, Alibaba, Mail.ru  '
            'Headspace '
            'appappappbughttps://www.engadget.com/2017/10/20/google-bug-bounty-program-android-apps/\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t MinecraftXbox One '
            'X4K.jpgE3 '
            '2017MinecraftGears of War 4Forza '
            'Horizon 3Killer InstinctHalo Wars 24KSuper Duper '
            'Graphics...XD4K '
            '... 4K '
            'Better '
            'TogetherMinecraftMinecraftSuper '
            'Duper Graphics packXbox One '
            'X4KPCMinecraftMinecraftMinecraftSkinMinecraft\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t splash '
            'screenappappAndroid '
            'Oreo\xa0Android 8.0\xa0\xa0splash screen '
            'APIAPIdrawableappActivityAndroid '
            'OreodrawableSplashActivityAPI\xa0'
            'Android Developers\xa0'
            '413AOSPAndroid '
            'O\xa0AOSP commit\xa0'
            'APIAndroid '
            'Oreo\xa0APIAndroid '
            'Open Source ProjectAndroid Oreo Adds a Splash Screen API so '
            'Developers can Easily Build App Loading Screens\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:59:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 03:59:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            '517I/Ohttps://events.google.com/io/\xa0'
            'GoogleI/O Live '
            'Widget/517-19I/Oyoutubef '
            'q '
            'https://events.google.com/io/widget/?utm_source=google&utm_medium=social&utm_campaign=gplus\xa0'
            '\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 03:59:20 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 03:59:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 1.397545,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 10, 59, 20, 684437),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/INFO': 10,
 'memusage/max': 52924416,
 'memusage/startup': 52924416,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 10, 59, 19, 286892)}
2020-04-16 03:59:20 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 04:01:06 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 04:01:06 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 04:01:06 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 04:01:06 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 04:01:06 [scrapy.extensions.telnet] INFO: Telnet Password: 4e46de7da5b1a8a6
2020-04-16 04:01:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 04:01:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 04:01:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 04:01:06 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-04-16 04:01:06 [scrapy.core.engine] INFO: Spider opened
2020-04-16 04:01:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 04:01:06 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 04:01:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 04:01:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Android  Android '
            'Android  Google '
            'Android Google  4 Google  10  '
            'Google Pixel  Android Nought  7%  '
            'Android 7.1  0.5%2015  Android 6.0  2014  '
            'Android 5.0  31.2%  32 % Android N Android O '
            'googleGoogle  Android N '
            ' Android O '
            ' Android '
            ' Android O  Android '
            'Google Project\xa0Treble Google  '
            'Project Treble  Android  OEM '
            'Android  Google '
            ' Android '
            'Android O  '
            '9to5google Google  '
            'Android  QualcomMediatek LG '
            ' Android '
            ' '
            'Android  Google Google '
            ' Google Pixel  Nexus  cdnforo Project Treble  '
            'Android Google '
            'Vendor '
            'ImplementaTIonOEM '
            ' '
            'AndroidfonpitOEM '
            'Google  OEM  '
            'Android AOSPOEM  '
            'Android  OEM  AndroidAndroid O '
            'Google Project Treble Android O Android '
            'Google I/O 2017  5  18 '
            'ifanrandroidcommunityhttp://www.ifanr.com/835683\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'appAndroid '
            'batbatapphttps://green-android.org/app-convention.html\xa0'
            'AndroidAndroidAndroidAndroidAndroidAndroidGitHub '
            'issue trackerAndroidAndroid '
            'OAndroidTarget '
            'SDK Version >= 24 (Android 7.0)Project SvelteAndroid '
            '7READ_PHONE_STATEIMEIAndroid '
            '6.0Android\xa0'
            'SDKCPUIOCPUAlarmJobScheduler301CPUGoogleProject '
            'Volta121Android4.4 '
            '(Background-free)CPUIO '
            'Android O '
            '(Background-free)Android '
            'O3PendingIntentJobSchedulerAndroid '
            '5.0AndroidManifest.xmlAndroid '
            'OAndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xmlandroid.net.conn.CONNECTIVITY_CHANGE\xa0'
            'Android '
            '7android.hardware.action.NEW_PICTURE\xa0'
            'android.hardware.action.NEW_VIDEO\xa0'
            'android.net.wifi.SCAN_RESULTS\xa0 LocationManager '
            'android.intent.action.USER_PRESENT\xa0'
            'android.intent.action.ACTION_POWER_CONNECTED\xa0 '
            'JobScheduler '
            'android.intent.action.ACTION_POWER_DISCONNECTED\xa0 '
            'JobScheduler android.intent.action.MEDIA_\xa0'
            'AndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xml<receiver\xa0...\xa0'
            'android:enabled="@bool/until_api_21">/src/main/res/values/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">true</bool>\n'
            '</resources>/src/main/res/values-v21/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">false</bool>\n'
            '</resources>Android 4.4 / '
            'AndroidAndroid '
            '4.4Storage Access '
            'FrameworkAPITFUSB '
            'OTGNASDropboxGoogle '
            'Drive4.4AndroidAndroid '
            '4.4<uses-permission '
            'android:name="android.permission.WRITE_EXTERNAL_STORAGE" '
            'android:maxSdkVersion="18" '
            '/>Context.getExternalFilesDir()\xa0'
            'Context.getExternalCacheDir()\xa0APIAndroid '
            '4.4Android '
            '4.4Google '
            'PlayGoogle PlayGoogle '
            'PlayAndroidAndroidGoogle '
            'PlayAndroidGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'Play\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'AOL50Oath15%35%Altaba19952261322AOL50Oath15%35%AltabaAltaba6002300Verizon200015%1995 '
            'David FiloCEO2001Terry '
            'Semel10001.62Verizon748.344.82300300200020125Tumblr2300254%1553.12112%Terry '
            'SemelCarol '
            'BartzFacebookInstagramSnapchat199532100022SlackWhatsAppVerizon*************************************************************323Verizon55106.5150YahooMozillaAppFantasy2012iOSAndroid41400SSLHTML5HTTPS5201320142Mavens '
            'GAAP2042%20122102011GAAP1510BrightRollFlurry1720127451805303501028.6427%IPO1.22IPO908FYIPB&JHackdays48%25%17.5770Yaho-o-ooMarissahttp://netsmell.com/post/yahoo-45b-acquired-by.html\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'WannaCryWannaCry150NSAWannaCryNSA(moderate '
            'confidence)WannaCryWannaCryNSAIPLazarus '
            'GroupWannaCry300cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  GMS '
            'OPPOvivoUnified '
            'Push '
            'ServiceUPSAPNS '
            'App  App '
            ' '
            'Android '
            'AppApp '
            'API  API '
            'AppSDKSDK '
            'ROM API '
            'SDKIT\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Java  James Gosling\xa0 AWS '
            'James Gosling  Facebook  '
            'Gosling  AWS '
            'Gosling  IoT  IoT '
            'James Gosling  Sun Microsystems  Java '
            ' Sun  '
            'Google Liquid Robotics  Wave '
            'GliderGosling '
            ' '
            '\xa0'
            '[http://www.oschina.net]https://www.oschina.net/news/85108/aws-signs-java-father-james-gosling\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t \xa0 \xa0 \xa0 \xa0'
            'GoogleUdacity75000AndroidGoogleUdacity20152016100010000Google '
            'EMEAMatt '
            'BrittinUdacity75000Google202050AndroidWebUdacity15000cnbetahttp://www.cnbeta.com/articles/tech/648715.htm\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Fuchsia Git '
            ' UI Android  '
            'Chrome OS Fuchsia  Linux    '
            '"Magenta" FuchsiaLinux  GPL \xa0'
            'BSD 3 clause,\xa0MIT, \xa0Apache 2.0\xa0 Linux '
            ' Android  Linux  Google Pixel '
            ' 2014  Linux Kernel 3.18 \xa0Magenta '
            ' Fuchsia '
            ' Android '
            'Fuchsia '
            "\xa0Google's Flutter SDK\xa0"
            ' Android  iOS Flutter app  Dart '
            'Flutter SDK "Escher"\xa0Vulkan '
            ' shadow-heavy Material Design '
            'Fuchsia  UI  ArmadilloFuchsia  Flutter '
            'SDK Armadillo  Google  Fuchsia '
            ' UI  Android APK  Android  UI '
            '20% '
            'Fuchsia  Fuchsia IRC Fuchsia  Travis '
            'Geiselbrecht  20% '
            'Android '
            ' UI  '
            'Dart  Linux  GPL Java \xa0'
            'Oracle  Android  '
            'Android  Fuchsia  2020 '
            'Fuchsia '
            'arsTECHNICAhttp://www.oschina.net/news/84594/google-fuchsia-smartphone-os-dumps-linux-has-a-wild-new-ui\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  bug  Play store  app '
            'bugapp\xa0'
            'HackerOne '
            'issue1000app\xa0'
            'Dropbox, Duolingo, Line, Snapchat, Tinder, Alibaba, Mail.ru  '
            'Headspace '
            'appappappbughttps://www.engadget.com/2017/10/20/google-bug-bounty-program-android-apps/\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Google  Android 8.0 '
            'Oreo Android Beta Google  Oreo '
            'Google  Nexus  Pixel  '
            'Android 8.0 Google  '
            'EssentialHTCKyoceraMotorolaHMD '
            'GlobalNokia '
            'Android 8.0  2018  Pixel  '
            'HTC  LG  HTC  U11  Android '
            '8.0cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Windows 10 SWindows '
            '10 Windows 10 SWindows RTWindows 10 '
            'SEdgeBingGoogle '
            'ChromeWindows StoreZDNetWindows '
            'StoreDekstop BridgeWindows '
            'StoreEdgeUWP '
            'EdgeHTMLJavaScriptWindows '
            'StoreWindows PlatformHTMLJavaScriptWindows '
            'StoreWindows '
            '10 '
            'ProiOSWebKitiOS '
            'ChromebookChromeGoogleChrome '
            'OSAndroidWindowsChromeFirefoxWindows '
            '10Windows 10 SChromebook '
            'EdgeChromeFirefoxcnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t MinecraftXbox One '
            'X4K.jpgE3 '
            '2017MinecraftGears of War 4Forza '
            'Horizon 3Killer InstinctHalo Wars 24KSuper Duper '
            'Graphics...XD4K '
            '... 4K '
            'Better '
            'TogetherMinecraftMinecraftSuper '
            'Duper Graphics packXbox One '
            'X4KPCMinecraftMinecraftMinecraftSkinMinecraft\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t splash '
            'screenappappAndroid '
            'Oreo\xa0Android 8.0\xa0\xa0splash screen '
            'APIAPIdrawableappActivityAndroid '
            'OreodrawableSplashActivityAPI\xa0'
            'Android Developers\xa0'
            '413AOSPAndroid '
            'O\xa0AOSP commit\xa0'
            'APIAndroid '
            'Oreo\xa0APIAndroid '
            'Open Source ProjectAndroid Oreo Adds a Splash Screen API so '
            'Developers can Easily Build App Loading Screens\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t AndroidAndy '
            'RubinEssential PhoneEssential '
            'PhoneEssential '
            'PhoneEssential '
            'Phone8354GB128GB5.712560 x 1312 '
            'QHD19:103040mAh360UHD '
            '(3840x1920) 30Fps/DockEssential '
            'Phone1200 '
            '8004KEssential7.1.1ITEssential '
            'Phone3.5mmUSB-C5.069947893607495132 '
            'it\xa0http://mt.sohu.com/20170530/n495020791.shtml\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            '517I/Ohttps://events.google.com/io/\xa0'
            'GoogleI/O Live '
            'Widget/517-19I/Oyoutubef '
            'q '
            'https://events.google.com/io/widget/?utm_source=google&utm_medium=social&utm_campaign=gplus\xa0'
            '\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:09 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 04:01:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 3.581831,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 11, 1, 9, 706447),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/INFO': 10,
 'memusage/max': 52969472,
 'memusage/startup': 52969472,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 11, 1, 6, 124616)}
2020-04-16 04:01:09 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 04:01:26 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 04:01:26 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 04:01:26 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 04:01:26 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 04:01:26 [scrapy.extensions.telnet] INFO: Telnet Password: 8da68c6625be34c5
2020-04-16 04:01:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 04:01:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 04:01:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 04:01:26 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-16 04:01:26 [scrapy.core.engine] INFO: Spider opened
2020-04-16 04:01:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 04:01:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 04:01:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 04:01:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Windows 10 SWindows '
            '10 Windows 10 SWindows RTWindows 10 '
            'SEdgeBingGoogle '
            'ChromeWindows StoreZDNetWindows '
            'StoreDekstop BridgeWindows '
            'StoreEdgeUWP '
            'EdgeHTMLJavaScriptWindows '
            'StoreWindows PlatformHTMLJavaScriptWindows '
            'StoreWindows '
            '10 '
            'ProiOSWebKitiOS '
            'ChromebookChromeGoogleChrome '
            'OSAndroidWindowsChromeFirefoxWindows '
            '10Windows 10 SChromebook '
            'EdgeChromeFirefoxcnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Android  Android '
            'Android  Google '
            'Android Google  4 Google  10  '
            'Google Pixel  Android Nought  7%  '
            'Android 7.1  0.5%2015  Android 6.0  2014  '
            'Android 5.0  31.2%  32 % Android N Android O '
            'googleGoogle  Android N '
            ' Android O '
            ' Android '
            ' Android O  Android '
            'Google Project\xa0Treble Google  '
            'Project Treble  Android  OEM '
            'Android  Google '
            ' Android '
            'Android O  '
            '9to5google Google  '
            'Android  QualcomMediatek LG '
            ' Android '
            ' '
            'Android  Google Google '
            ' Google Pixel  Nexus  cdnforo Project Treble  '
            'Android Google '
            'Vendor '
            'ImplementaTIonOEM '
            ' '
            'AndroidfonpitOEM '
            'Google  OEM  '
            'Android AOSPOEM  '
            'Android  OEM  AndroidAndroid O '
            'Google Project Treble Android O Android '
            'Google I/O 2017  5  18 '
            'ifanrandroidcommunityhttp://www.ifanr.com/835683\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t AndroidAndy '
            'RubinEssential PhoneEssential '
            'PhoneEssential '
            'PhoneEssential '
            'Phone8354GB128GB5.712560 x 1312 '
            'QHD19:103040mAh360UHD '
            '(3840x1920) 30Fps/DockEssential '
            'Phone1200 '
            '8004KEssential7.1.1ITEssential '
            'Phone3.5mmUSB-C5.069947893607495132 '
            'it\xa0http://mt.sohu.com/20170530/n495020791.shtml\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  GMS '
            'OPPOvivoUnified '
            'Push '
            'ServiceUPSAPNS '
            'App  App '
            ' '
            'Android '
            'AppApp '
            'API  API '
            'AppSDKSDK '
            'ROM API '
            'SDKIT\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Java  James Gosling\xa0 AWS '
            'James Gosling  Facebook  '
            'Gosling  AWS '
            'Gosling  IoT  IoT '
            'James Gosling  Sun Microsystems  Java '
            ' Sun  '
            'Google Liquid Robotics  Wave '
            'GliderGosling '
            ' '
            '\xa0'
            '[http://www.oschina.net]https://www.oschina.net/news/85108/aws-signs-java-father-james-gosling\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            '517I/Ohttps://events.google.com/io/\xa0'
            'GoogleI/O Live '
            'Widget/517-19I/Oyoutubef '
            'q '
            'https://events.google.com/io/widget/?utm_source=google&utm_medium=social&utm_campaign=gplus\xa0'
            '\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Fuchsia Git '
            ' UI Android  '
            'Chrome OS Fuchsia  Linux    '
            '"Magenta" FuchsiaLinux  GPL \xa0'
            'BSD 3 clause,\xa0MIT, \xa0Apache 2.0\xa0 Linux '
            ' Android  Linux  Google Pixel '
            ' 2014  Linux Kernel 3.18 \xa0Magenta '
            ' Fuchsia '
            ' Android '
            'Fuchsia '
            "\xa0Google's Flutter SDK\xa0"
            ' Android  iOS Flutter app  Dart '
            'Flutter SDK "Escher"\xa0Vulkan '
            ' shadow-heavy Material Design '
            'Fuchsia  UI  ArmadilloFuchsia  Flutter '
            'SDK Armadillo  Google  Fuchsia '
            ' UI  Android APK  Android  UI '
            '20% '
            'Fuchsia  Fuchsia IRC Fuchsia  Travis '
            'Geiselbrecht  20% '
            'Android '
            ' UI  '
            'Dart  Linux  GPL Java \xa0'
            'Oracle  Android  '
            'Android  Fuchsia  2020 '
            'Fuchsia '
            'arsTECHNICAhttp://www.oschina.net/news/84594/google-fuchsia-smartphone-os-dumps-linux-has-a-wild-new-ui\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'appAndroid '
            'batbatapphttps://green-android.org/app-convention.html\xa0'
            'AndroidAndroidAndroidAndroidAndroidAndroidGitHub '
            'issue trackerAndroidAndroid '
            'OAndroidTarget '
            'SDK Version >= 24 (Android 7.0)Project SvelteAndroid '
            '7READ_PHONE_STATEIMEIAndroid '
            '6.0Android\xa0'
            'SDKCPUIOCPUAlarmJobScheduler301CPUGoogleProject '
            'Volta121Android4.4 '
            '(Background-free)CPUIO '
            'Android O '
            '(Background-free)Android '
            'O3PendingIntentJobSchedulerAndroid '
            '5.0AndroidManifest.xmlAndroid '
            'OAndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xmlandroid.net.conn.CONNECTIVITY_CHANGE\xa0'
            'Android '
            '7android.hardware.action.NEW_PICTURE\xa0'
            'android.hardware.action.NEW_VIDEO\xa0'
            'android.net.wifi.SCAN_RESULTS\xa0 LocationManager '
            'android.intent.action.USER_PRESENT\xa0'
            'android.intent.action.ACTION_POWER_CONNECTED\xa0 '
            'JobScheduler '
            'android.intent.action.ACTION_POWER_DISCONNECTED\xa0 '
            'JobScheduler android.intent.action.MEDIA_\xa0'
            'AndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xml<receiver\xa0...\xa0'
            'android:enabled="@bool/until_api_21">/src/main/res/values/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">true</bool>\n'
            '</resources>/src/main/res/values-v21/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">false</bool>\n'
            '</resources>Android 4.4 / '
            'AndroidAndroid '
            '4.4Storage Access '
            'FrameworkAPITFUSB '
            'OTGNASDropboxGoogle '
            'Drive4.4AndroidAndroid '
            '4.4<uses-permission '
            'android:name="android.permission.WRITE_EXTERNAL_STORAGE" '
            'android:maxSdkVersion="18" '
            '/>Context.getExternalFilesDir()\xa0'
            'Context.getExternalCacheDir()\xa0APIAndroid '
            '4.4Android '
            '4.4Google '
            'PlayGoogle PlayGoogle '
            'PlayAndroidAndroidGoogle '
            'PlayAndroidGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'Play\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'WannaCryWannaCry150NSAWannaCryNSA(moderate '
            'confidence)WannaCryWannaCryNSAIPLazarus '
            'GroupWannaCry300cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:01:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'AOL50Oath15%35%Altaba19952261322AOL50Oath15%35%AltabaAltaba6002300Verizon200015%1995 '
            'David FiloCEO2001Terry '
            'Semel10001.62Verizon748.344.82300300200020125Tumblr2300254%1553.12112%Terry '
            'SemelCarol '
            'BartzFacebookInstagramSnapchat199532100022SlackWhatsAppVerizon*************************************************************323Verizon55106.5150YahooMozillaAppFantasy2012iOSAndroid41400SSLHTML5HTTPS5201320142Mavens '
            'GAAP2042%20122102011GAAP1510BrightRollFlurry1720127451805303501028.6427%IPO1.22IPO908FYIPB&JHackdays48%25%17.5770Yaho-o-ooMarissahttp://netsmell.com/post/yahoo-45b-acquired-by.html\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t \xa0 \xa0 \xa0 \xa0'
            'GoogleUdacity75000AndroidGoogleUdacity20152016100010000Google '
            'EMEAMatt '
            'BrittinUdacity75000Google202050AndroidWebUdacity15000cnbetahttp://www.cnbeta.com/articles/tech/648715.htm\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  bug  Play store  app '
            'bugapp\xa0'
            'HackerOne '
            'issue1000app\xa0'
            'Dropbox, Duolingo, Line, Snapchat, Tinder, Alibaba, Mail.ru  '
            'Headspace '
            'appappappbughttps://www.engadget.com/2017/10/20/google-bug-bounty-program-android-apps/\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t MinecraftXbox One '
            'X4K.jpgE3 '
            '2017MinecraftGears of War 4Forza '
            'Horizon 3Killer InstinctHalo Wars 24KSuper Duper '
            'Graphics...XD4K '
            '... 4K '
            'Better '
            'TogetherMinecraftMinecraftSuper '
            'Duper Graphics packXbox One '
            'X4KPCMinecraftMinecraftMinecraftSkinMinecraft\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t splash '
            'screenappappAndroid '
            'Oreo\xa0Android 8.0\xa0\xa0splash screen '
            'APIAPIdrawableappActivityAndroid '
            'OreodrawableSplashActivityAPI\xa0'
            'Android Developers\xa0'
            '413AOSPAndroid '
            'O\xa0AOSP commit\xa0'
            'APIAndroid '
            'Oreo\xa0APIAndroid '
            'Open Source ProjectAndroid Oreo Adds a Splash Screen API so '
            'Developers can Easily Build App Loading Screens\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Google  Android 8.0 '
            'Oreo Android Beta Google  Oreo '
            'Google  Nexus  Pixel  '
            'Android 8.0 Google  '
            'EssentialHTCKyoceraMotorolaHMD '
            'GlobalNokia '
            'Android 8.0  2018  Pixel  '
            'HTC  LG  HTC  U11  Android '
            '8.0cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:01:28 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 04:01:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 1.918485,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 11, 1, 28, 38842),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/INFO': 10,
 'memusage/max': 54366208,
 'memusage/startup': 54366208,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 11, 1, 26, 120357)}
2020-04-16 04:01:28 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 04:02:57 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 04:02:57 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 04:02:57 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 04:02:57 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 04:02:57 [scrapy.extensions.telnet] INFO: Telnet Password: 1c154e4aa53686eb
2020-04-16 04:02:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2020-04-16 04:02:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 04:02:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 04:02:57 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-16 04:02:57 [scrapy.core.engine] INFO: Spider opened
2020-04-16 04:02:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 04:02:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 04:02:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 04:02:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:02:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:02:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:02:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:02:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:02:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:02:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:02:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:02:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Windows 10 SWindows '
            '10 Windows 10 SWindows RTWindows 10 '
            'SEdgeBingGoogle '
            'ChromeWindows StoreZDNetWindows '
            'StoreDekstop BridgeWindows '
            'StoreEdgeUWP '
            'EdgeHTMLJavaScriptWindows '
            'StoreWindows PlatformHTMLJavaScriptWindows '
            'StoreWindows '
            '10 '
            'ProiOSWebKitiOS '
            'ChromebookChromeGoogleChrome '
            'OSAndroidWindowsChromeFirefoxWindows '
            '10Windows 10 SChromebook '
            'EdgeChromeFirefoxcnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:02:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Java  James Gosling\xa0 AWS '
            'James Gosling  Facebook  '
            'Gosling  AWS '
            'Gosling  IoT  IoT '
            'James Gosling  Sun Microsystems  Java '
            ' Sun  '
            'Google Liquid Robotics  Wave '
            'GliderGosling '
            ' '
            '\xa0'
            '[http://www.oschina.net]https://www.oschina.net/news/85108/aws-signs-java-father-james-gosling\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:02:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  GMS '
            'OPPOvivoUnified '
            'Push '
            'ServiceUPSAPNS '
            'App  App '
            ' '
            'Android '
            'AppApp '
            'API  API '
            'AppSDKSDK '
            'ROM API '
            'SDKIT\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:02:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Android  Android '
            'Android  Google '
            'Android Google  4 Google  10  '
            'Google Pixel  Android Nought  7%  '
            'Android 7.1  0.5%2015  Android 6.0  2014  '
            'Android 5.0  31.2%  32 % Android N Android O '
            'googleGoogle  Android N '
            ' Android O '
            ' Android '
            ' Android O  Android '
            'Google Project\xa0Treble Google  '
            'Project Treble  Android  OEM '
            'Android  Google '
            ' Android '
            'Android O  '
            '9to5google Google  '
            'Android  QualcomMediatek LG '
            ' Android '
            ' '
            'Android  Google Google '
            ' Google Pixel  Nexus  cdnforo Project Treble  '
            'Android Google '
            'Vendor '
            'ImplementaTIonOEM '
            ' '
            'AndroidfonpitOEM '
            'Google  OEM  '
            'Android AOSPOEM  '
            'Android  OEM  AndroidAndroid O '
            'Google Project Treble Android O Android '
            'Google I/O 2017  5  18 '
            'ifanrandroidcommunityhttp://www.ifanr.com/835683\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:02:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            '517I/Ohttps://events.google.com/io/\xa0'
            'GoogleI/O Live '
            'Widget/517-19I/Oyoutubef '
            'q '
            'https://events.google.com/io/widget/?utm_source=google&utm_medium=social&utm_campaign=gplus\xa0'
            '\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:02:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t AndroidAndy '
            'RubinEssential PhoneEssential '
            'PhoneEssential '
            'PhoneEssential '
            'Phone8354GB128GB5.712560 x 1312 '
            'QHD19:103040mAh360UHD '
            '(3840x1920) 30Fps/DockEssential '
            'Phone1200 '
            '8004KEssential7.1.1ITEssential '
            'Phone3.5mmUSB-C5.069947893607495132 '
            'it\xa0http://mt.sohu.com/20170530/n495020791.shtml\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:02:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:02:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:02:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:02:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:02:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'appAndroid '
            'batbatapphttps://green-android.org/app-convention.html\xa0'
            'AndroidAndroidAndroidAndroidAndroidAndroidGitHub '
            'issue trackerAndroidAndroid '
            'OAndroidTarget '
            'SDK Version >= 24 (Android 7.0)Project SvelteAndroid '
            '7READ_PHONE_STATEIMEIAndroid '
            '6.0Android\xa0'
            'SDKCPUIOCPUAlarmJobScheduler301CPUGoogleProject '
            'Volta121Android4.4 '
            '(Background-free)CPUIO '
            'Android O '
            '(Background-free)Android '
            'O3PendingIntentJobSchedulerAndroid '
            '5.0AndroidManifest.xmlAndroid '
            'OAndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xmlandroid.net.conn.CONNECTIVITY_CHANGE\xa0'
            'Android '
            '7android.hardware.action.NEW_PICTURE\xa0'
            'android.hardware.action.NEW_VIDEO\xa0'
            'android.net.wifi.SCAN_RESULTS\xa0 LocationManager '
            'android.intent.action.USER_PRESENT\xa0'
            'android.intent.action.ACTION_POWER_CONNECTED\xa0 '
            'JobScheduler '
            'android.intent.action.ACTION_POWER_DISCONNECTED\xa0 '
            'JobScheduler android.intent.action.MEDIA_\xa0'
            'AndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xml<receiver\xa0...\xa0'
            'android:enabled="@bool/until_api_21">/src/main/res/values/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">true</bool>\n'
            '</resources>/src/main/res/values-v21/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">false</bool>\n'
            '</resources>Android 4.4 / '
            'AndroidAndroid '
            '4.4Storage Access '
            'FrameworkAPITFUSB '
            'OTGNASDropboxGoogle '
            'Drive4.4AndroidAndroid '
            '4.4<uses-permission '
            'android:name="android.permission.WRITE_EXTERNAL_STORAGE" '
            'android:maxSdkVersion="18" '
            '/>Context.getExternalFilesDir()\xa0'
            'Context.getExternalCacheDir()\xa0APIAndroid '
            '4.4Android '
            '4.4Google '
            'PlayGoogle PlayGoogle '
            'PlayAndroidAndroidGoogle '
            'PlayAndroidGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'Play\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:02:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:02:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:02:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'WannaCryWannaCry150NSAWannaCryNSA(moderate '
            'confidence)WannaCryWannaCryNSAIPLazarus '
            'GroupWannaCry300cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:02:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'AOL50Oath15%35%Altaba19952261322AOL50Oath15%35%AltabaAltaba6002300Verizon200015%1995 '
            'David FiloCEO2001Terry '
            'Semel10001.62Verizon748.344.82300300200020125Tumblr2300254%1553.12112%Terry '
            'SemelCarol '
            'BartzFacebookInstagramSnapchat199532100022SlackWhatsAppVerizon*************************************************************323Verizon55106.5150YahooMozillaAppFantasy2012iOSAndroid41400SSLHTML5HTTPS5201320142Mavens '
            'GAAP2042%20122102011GAAP1510BrightRollFlurry1720127451805303501028.6427%IPO1.22IPO908FYIPB&JHackdays48%25%17.5770Yaho-o-ooMarissahttp://netsmell.com/post/yahoo-45b-acquired-by.html\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:02:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t splash '
            'screenappappAndroid '
            'Oreo\xa0Android 8.0\xa0\xa0splash screen '
            'APIAPIdrawableappActivityAndroid '
            'OreodrawableSplashActivityAPI\xa0'
            'Android Developers\xa0'
            '413AOSPAndroid '
            'O\xa0AOSP commit\xa0'
            'APIAndroid '
            'Oreo\xa0APIAndroid '
            'Open Source ProjectAndroid Oreo Adds a Splash Screen API so '
            'Developers can Easily Build App Loading Screens\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:02:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t \xa0 \xa0 \xa0 \xa0'
            'GoogleUdacity75000AndroidGoogleUdacity20152016100010000Google '
            'EMEAMatt '
            'BrittinUdacity75000Google202050AndroidWebUdacity15000cnbetahttp://www.cnbeta.com/articles/tech/648715.htm\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:02:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t MinecraftXbox One '
            'X4K.jpgE3 '
            '2017MinecraftGears of War 4Forza '
            'Horizon 3Killer InstinctHalo Wars 24KSuper Duper '
            'Graphics...XD4K '
            '... 4K '
            'Better '
            'TogetherMinecraftMinecraftSuper '
            'Duper Graphics packXbox One '
            'X4KPCMinecraftMinecraftMinecraftSkinMinecraft\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:02:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  bug  Play store  app '
            'bugapp\xa0'
            'HackerOne '
            'issue1000app\xa0'
            'Dropbox, Duolingo, Line, Snapchat, Tinder, Alibaba, Mail.ru  '
            'Headspace '
            'appappappbughttps://www.engadget.com/2017/10/20/google-bug-bounty-program-android-apps/\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:02:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Google  Android 8.0 '
            'Oreo Android Beta Google  Oreo '
            'Google  Nexus  Pixel  '
            'Android 8.0 Google  '
            'EssentialHTCKyoceraMotorolaHMD '
            'GlobalNokia '
            'Android 8.0  2018  Pixel  '
            'HTC  LG  HTC  U11  Android '
            '8.0cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:02:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:02:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
{'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Fuchsia Git '
            ' UI Android  '
            'Chrome OS Fuchsia  Linux    '
            '"Magenta" FuchsiaLinux  GPL \xa0'
            'BSD 3 clause,\xa0MIT, \xa0Apache 2.0\xa0 Linux '
            ' Android  Linux  Google Pixel '
            ' 2014  Linux Kernel 3.18 \xa0Magenta '
            ' Fuchsia '
            ' Android '
            'Fuchsia '
            "\xa0Google's Flutter SDK\xa0"
            ' Android  iOS Flutter app  Dart '
            'Flutter SDK "Escher"\xa0Vulkan '
            ' shadow-heavy Material Design '
            'Fuchsia  UI  ArmadilloFuchsia  Flutter '
            'SDK Armadillo  Google  Fuchsia '
            ' UI  Android APK  Android  UI '
            '20% '
            'Fuchsia  Fuchsia IRC Fuchsia  Travis '
            'Geiselbrecht  20% '
            'Android '
            ' UI  '
            'Dart  Linux  GPL Java \xa0'
            'Oracle  Android  '
            'Android  Fuchsia  2020 '
            'Fuchsia '
            'arsTECHNICAhttp://www.oschina.net/news/84594/google-fuchsia-smartphone-os-dumps-linux-has-a-wild-new-ui\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
2020-04-16 04:02:59 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 04:02:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 1.429378,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 11, 2, 59, 280287),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/INFO': 10,
 'memusage/max': 54128640,
 'memusage/startup': 54128640,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 11, 2, 57, 850909)}
2020-04-16 04:02:59 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 04:06:19 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 04:06:19 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 04:06:19 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 04:06:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 04:06:19 [scrapy.extensions.telnet] INFO: Telnet Password: f6ee773e445f3a47
2020-04-16 04:06:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-04-16 04:06:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 04:06:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 04:06:20 [twisted] CRITICAL: Unhandled error in Deferred:
2020-04-16 04:06:20 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/crawler.py", line 89, in crawl
    self.engine = self._create_engine()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/crawler.py", line 103, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/middleware.py", line 35, in from_settings
    mw = create_instance(mwcls, settings, crawler)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/misc.py", line 146, in create_instance
    return objcls.from_crawler(crawler, *args, **kwargs)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 23, in from_crawler
    return cls(host=host,user=user,password=pwd,database=database,port=port)
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 14, in __init__
    self.cursor = self.connects
AttributeError: 'PaoboriziPipeline' object has no attribute 'connects'
2020-04-16 04:06:40 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 04:06:40 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 04:06:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 04:06:40 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 04:06:40 [scrapy.extensions.telnet] INFO: Telnet Password: 9257c42f7786aa8d
2020-04-16 04:06:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2020-04-16 04:06:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 04:06:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 04:06:40 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-16 04:06:40 [scrapy.core.engine] INFO: Spider opened
2020-04-16 04:06:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 04:06:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 04:06:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 04:06:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:06:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:06:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
None
2020-04-16 04:06:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
None
2020-04-16 04:06:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:06:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:06:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:06:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:06:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
None
2020-04-16 04:06:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
None
2020-04-16 04:06:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
None
2020-04-16 04:06:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
None
2020-04-16 04:06:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:06:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:06:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:06:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:06:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
None
2020-04-16 04:06:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
None
2020-04-16 04:06:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
None
2020-04-16 04:06:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
None
2020-04-16 04:06:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:06:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
None
2020-04-16 04:06:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:06:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:06:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
None
2020-04-16 04:06:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
None
2020-04-16 04:06:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:06:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:06:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
None
2020-04-16 04:06:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
None
2020-04-16 04:06:42 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 04:06:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 2.084909,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 11, 6, 42, 250605),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/INFO': 10,
 'memusage/max': 55070720,
 'memusage/startup': 55070720,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 11, 6, 40, 165696)}
2020-04-16 04:06:42 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 04:07:30 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 04:07:30 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 04:07:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 04:07:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 04:07:30 [scrapy.extensions.telnet] INFO: Telnet Password: 08e62e49a5328f86
2020-04-16 04:07:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage']
2020-04-16 04:07:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 04:07:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 04:07:30 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-16 04:07:30 [scrapy.core.engine] INFO: Spider opened
2020-04-16 04:07:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 04:07:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 04:07:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 04:07:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:07:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:07:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:07:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:07:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:07:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:07:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:07:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:07:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:07:33 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Java  James Gosling\xa0 AWS '
            'James Gosling  Facebook  '
            'Gosling  AWS '
            'Gosling  IoT  IoT '
            'James Gosling  Sun Microsystems  Java '
            ' Sun  '
            'Google Liquid Robotics  Wave '
            'GliderGosling '
            ' '
            '\xa0'
            '[http://www.oschina.net]https://www.oschina.net/news/85108/aws-signs-java-father-james-gosling\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 28, in process_item
    for key,value in item:
ValueError: too many values to unpack (expected 2)
2020-04-16 04:07:33 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  GMS '
            'OPPOvivoUnified '
            'Push '
            'ServiceUPSAPNS '
            'App  App '
            ' '
            'Android '
            'AppApp '
            'API  API '
            'AppSDKSDK '
            'ROM API '
            'SDKIT\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 28, in process_item
    for key,value in item:
ValueError: too many values to unpack (expected 2)
2020-04-16 04:07:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:07:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:07:33 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Fuchsia Git '
            ' UI Android  '
            'Chrome OS Fuchsia  Linux    '
            '"Magenta" FuchsiaLinux  GPL \xa0'
            'BSD 3 clause,\xa0MIT, \xa0Apache 2.0\xa0 Linux '
            ' Android  Linux  Google Pixel '
            ' 2014  Linux Kernel 3.18 \xa0Magenta '
            ' Fuchsia '
            ' Android '
            'Fuchsia '
            "\xa0Google's Flutter SDK\xa0"
            ' Android  iOS Flutter app  Dart '
            'Flutter SDK "Escher"\xa0Vulkan '
            ' shadow-heavy Material Design '
            'Fuchsia  UI  ArmadilloFuchsia  Flutter '
            'SDK Armadillo  Google  Fuchsia '
            ' UI  Android APK  Android  UI '
            '20% '
            'Fuchsia  Fuchsia IRC Fuchsia  Travis '
            'Geiselbrecht  20% '
            'Android '
            ' UI  '
            'Dart  Linux  GPL Java \xa0'
            'Oracle  Android  '
            'Android  Fuchsia  2020 '
            'Fuchsia '
            'arsTECHNICAhttp://www.oschina.net/news/84594/google-fuchsia-smartphone-os-dumps-linux-has-a-wild-new-ui\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 28, in process_item
    for key,value in item:
ValueError: too many values to unpack (expected 2)
2020-04-16 04:07:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:07:33 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            '517I/Ohttps://events.google.com/io/\xa0'
            'GoogleI/O Live '
            'Widget/517-19I/Oyoutubef '
            'q '
            'https://events.google.com/io/widget/?utm_source=google&utm_medium=social&utm_campaign=gplus\xa0'
            '\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 28, in process_item
    for key,value in item:
ValueError: too many values to unpack (expected 2)
2020-04-16 04:07:33 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'appAndroid '
            'batbatapphttps://green-android.org/app-convention.html\xa0'
            'AndroidAndroidAndroidAndroidAndroidAndroidGitHub '
            'issue trackerAndroidAndroid '
            'OAndroidTarget '
            'SDK Version >= 24 (Android 7.0)Project SvelteAndroid '
            '7READ_PHONE_STATEIMEIAndroid '
            '6.0Android\xa0'
            'SDKCPUIOCPUAlarmJobScheduler301CPUGoogleProject '
            'Volta121Android4.4 '
            '(Background-free)CPUIO '
            'Android O '
            '(Background-free)Android '
            'O3PendingIntentJobSchedulerAndroid '
            '5.0AndroidManifest.xmlAndroid '
            'OAndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xmlandroid.net.conn.CONNECTIVITY_CHANGE\xa0'
            'Android '
            '7android.hardware.action.NEW_PICTURE\xa0'
            'android.hardware.action.NEW_VIDEO\xa0'
            'android.net.wifi.SCAN_RESULTS\xa0 LocationManager '
            'android.intent.action.USER_PRESENT\xa0'
            'android.intent.action.ACTION_POWER_CONNECTED\xa0 '
            'JobScheduler '
            'android.intent.action.ACTION_POWER_DISCONNECTED\xa0 '
            'JobScheduler android.intent.action.MEDIA_\xa0'
            'AndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xml<receiver\xa0...\xa0'
            'android:enabled="@bool/until_api_21">/src/main/res/values/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">true</bool>\n'
            '</resources>/src/main/res/values-v21/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">false</bool>\n'
            '</resources>Android 4.4 / '
            'AndroidAndroid '
            '4.4Storage Access '
            'FrameworkAPITFUSB '
            'OTGNASDropboxGoogle '
            'Drive4.4AndroidAndroid '
            '4.4<uses-permission '
            'android:name="android.permission.WRITE_EXTERNAL_STORAGE" '
            'android:maxSdkVersion="18" '
            '/>Context.getExternalFilesDir()\xa0'
            'Context.getExternalCacheDir()\xa0APIAndroid '
            '4.4Android '
            '4.4Google '
            'PlayGoogle PlayGoogle '
            'PlayAndroidAndroidGoogle '
            'PlayAndroidGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'Play\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 28, in process_item
    for key,value in item:
ValueError: too many values to unpack (expected 2)
2020-04-16 04:07:33 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Windows 10 SWindows '
            '10 Windows 10 SWindows RTWindows 10 '
            'SEdgeBingGoogle '
            'ChromeWindows StoreZDNetWindows '
            'StoreDekstop BridgeWindows '
            'StoreEdgeUWP '
            'EdgeHTMLJavaScriptWindows '
            'StoreWindows PlatformHTMLJavaScriptWindows '
            'StoreWindows '
            '10 '
            'ProiOSWebKitiOS '
            'ChromebookChromeGoogleChrome '
            'OSAndroidWindowsChromeFirefoxWindows '
            '10Windows 10 SChromebook '
            'EdgeChromeFirefoxcnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 28, in process_item
    for key,value in item:
ValueError: too many values to unpack (expected 2)
2020-04-16 04:07:33 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Android  Android '
            'Android  Google '
            'Android Google  4 Google  10  '
            'Google Pixel  Android Nought  7%  '
            'Android 7.1  0.5%2015  Android 6.0  2014  '
            'Android 5.0  31.2%  32 % Android N Android O '
            'googleGoogle  Android N '
            ' Android O '
            ' Android '
            ' Android O  Android '
            'Google Project\xa0Treble Google  '
            'Project Treble  Android  OEM '
            'Android  Google '
            ' Android '
            'Android O  '
            '9to5google Google  '
            'Android  QualcomMediatek LG '
            ' Android '
            ' '
            'Android  Google Google '
            ' Google Pixel  Nexus  cdnforo Project Treble  '
            'Android Google '
            'Vendor '
            'ImplementaTIonOEM '
            ' '
            'AndroidfonpitOEM '
            'Google  OEM  '
            'Android AOSPOEM  '
            'Android  OEM  AndroidAndroid O '
            'Google Project Treble Android O Android '
            'Google I/O 2017  5  18 '
            'ifanrandroidcommunityhttp://www.ifanr.com/835683\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 28, in process_item
    for key,value in item:
ValueError: too many values to unpack (expected 2)
2020-04-16 04:07:33 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t AndroidAndy '
            'RubinEssential PhoneEssential '
            'PhoneEssential '
            'PhoneEssential '
            'Phone8354GB128GB5.712560 x 1312 '
            'QHD19:103040mAh360UHD '
            '(3840x1920) 30Fps/DockEssential '
            'Phone1200 '
            '8004KEssential7.1.1ITEssential '
            'Phone3.5mmUSB-C5.069947893607495132 '
            'it\xa0http://mt.sohu.com/20170530/n495020791.shtml\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 28, in process_item
    for key,value in item:
ValueError: too many values to unpack (expected 2)
2020-04-16 04:07:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:07:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:07:33 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'WannaCryWannaCry150NSAWannaCryNSA(moderate '
            'confidence)WannaCryWannaCryNSAIPLazarus '
            'GroupWannaCry300cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 28, in process_item
    for key,value in item:
ValueError: too many values to unpack (expected 2)
2020-04-16 04:07:33 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'AOL50Oath15%35%Altaba19952261322AOL50Oath15%35%AltabaAltaba6002300Verizon200015%1995 '
            'David FiloCEO2001Terry '
            'Semel10001.62Verizon748.344.82300300200020125Tumblr2300254%1553.12112%Terry '
            'SemelCarol '
            'BartzFacebookInstagramSnapchat199532100022SlackWhatsAppVerizon*************************************************************323Verizon55106.5150YahooMozillaAppFantasy2012iOSAndroid41400SSLHTML5HTTPS5201320142Mavens '
            'GAAP2042%20122102011GAAP1510BrightRollFlurry1720127451805303501028.6427%IPO1.22IPO908FYIPB&JHackdays48%25%17.5770Yaho-o-ooMarissahttp://netsmell.com/post/yahoo-45b-acquired-by.html\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 28, in process_item
    for key,value in item:
ValueError: too many values to unpack (expected 2)
2020-04-16 04:07:33 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t MinecraftXbox One '
            'X4K.jpgE3 '
            '2017MinecraftGears of War 4Forza '
            'Horizon 3Killer InstinctHalo Wars 24KSuper Duper '
            'Graphics...XD4K '
            '... 4K '
            'Better '
            'TogetherMinecraftMinecraftSuper '
            'Duper Graphics packXbox One '
            'X4KPCMinecraftMinecraftMinecraftSkinMinecraft\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 28, in process_item
    for key,value in item:
ValueError: too many values to unpack (expected 2)
2020-04-16 04:07:33 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t splash '
            'screenappappAndroid '
            'Oreo\xa0Android 8.0\xa0\xa0splash screen '
            'APIAPIdrawableappActivityAndroid '
            'OreodrawableSplashActivityAPI\xa0'
            'Android Developers\xa0'
            '413AOSPAndroid '
            'O\xa0AOSP commit\xa0'
            'APIAndroid '
            'Oreo\xa0APIAndroid '
            'Open Source ProjectAndroid Oreo Adds a Splash Screen API so '
            'Developers can Easily Build App Loading Screens\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 28, in process_item
    for key,value in item:
ValueError: too many values to unpack (expected 2)
2020-04-16 04:07:33 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  bug  Play store  app '
            'bugapp\xa0'
            'HackerOne '
            'issue1000app\xa0'
            'Dropbox, Duolingo, Line, Snapchat, Tinder, Alibaba, Mail.ru  '
            'Headspace '
            'appappappbughttps://www.engadget.com/2017/10/20/google-bug-bounty-program-android-apps/\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 28, in process_item
    for key,value in item:
ValueError: too many values to unpack (expected 2)
2020-04-16 04:07:33 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t \xa0 \xa0 \xa0 \xa0'
            'GoogleUdacity75000AndroidGoogleUdacity20152016100010000Google '
            'EMEAMatt '
            'BrittinUdacity75000Google202050AndroidWebUdacity15000cnbetahttp://www.cnbeta.com/articles/tech/648715.htm\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 28, in process_item
    for key,value in item:
ValueError: too many values to unpack (expected 2)
2020-04-16 04:07:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:07:33 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Google  Android 8.0 '
            'Oreo Android Beta Google  Oreo '
            'Google  Nexus  Pixel  '
            'Android 8.0 Google  '
            'EssentialHTCKyoceraMotorolaHMD '
            'GlobalNokia '
            'Android 8.0  2018  Pixel  '
            'HTC  LG  HTC  U11  Android '
            '8.0cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 28, in process_item
    for key,value in item:
ValueError: too many values to unpack (expected 2)
2020-04-16 04:07:33 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 04:07:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 2.803849,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 11, 7, 33, 689107),
 'log_count/DEBUG': 16,
 'log_count/ERROR': 15,
 'log_count/INFO': 10,
 'memusage/max': 54800384,
 'memusage/startup': 54800384,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 11, 7, 30, 885258)}
2020-04-16 04:07:33 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 04:09:18 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 04:09:18 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 04:09:18 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 04:09:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 04:09:18 [scrapy.extensions.telnet] INFO: Telnet Password: e2f7065084499643
2020-04-16 04:09:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole']
2020-04-16 04:09:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 04:09:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 04:09:18 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-16 04:09:18 [scrapy.core.engine] INFO: Spider opened
2020-04-16 04:09:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 04:09:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 04:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 04:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:09:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
None
2020-04-16 04:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:09:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
None
2020-04-16 04:09:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
None
2020-04-16 04:09:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
None
2020-04-16 04:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:09:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
None
2020-04-16 04:09:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
None
2020-04-16 04:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:09:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
None
2020-04-16 04:09:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
None
2020-04-16 04:09:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
None
2020-04-16 04:09:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
None
2020-04-16 04:09:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
None
2020-04-16 04:09:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
None
2020-04-16 04:09:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
None
2020-04-16 04:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:09:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
None
2020-04-16 04:09:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:09:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
None
2020-04-16 04:09:20 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 04:09:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 1.426312,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 11, 9, 20, 392120),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/INFO': 10,
 'memusage/max': 55652352,
 'memusage/startup': 55652352,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 11, 9, 18, 965808)}
2020-04-16 04:09:20 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 04:10:34 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 04:10:34 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 04:10:34 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 04:10:34 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 04:10:34 [scrapy.extensions.telnet] INFO: Telnet Password: 44143240b9a20a0b
2020-04-16 04:10:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats']
2020-04-16 04:10:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 04:10:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 04:10:34 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-16 04:10:34 [scrapy.core.engine] INFO: Spider opened
2020-04-16 04:10:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 04:10:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 04:10:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 04:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:10:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
None
2020-04-16 04:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:10:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
None
2020-04-16 04:10:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
None
2020-04-16 04:10:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
None
2020-04-16 04:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:10:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
None
2020-04-16 04:10:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
None
2020-04-16 04:10:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
None
2020-04-16 04:10:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
None
2020-04-16 04:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:10:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
None
2020-04-16 04:10:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
None
2020-04-16 04:10:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
None
2020-04-16 04:10:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
None
2020-04-16 04:10:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
None
2020-04-16 04:10:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
None
2020-04-16 04:10:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
None
2020-04-16 04:10:35 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 04:10:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 0.620454,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 11, 10, 35, 431670),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/INFO': 10,
 'memusage/max': 55689216,
 'memusage/startup': 55689216,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 11, 10, 34, 811216)}
2020-04-16 04:10:35 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 04:13:56 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 04:13:56 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 04:13:56 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 04:13:56 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 04:13:56 [scrapy.extensions.telnet] INFO: Telnet Password: b8853e106378a18a
2020-04-16 04:13:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats']
2020-04-16 04:13:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 04:13:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 04:13:56 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-16 04:13:56 [scrapy.core.engine] INFO: Spider opened
2020-04-16 04:13:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 04:13:56 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 04:13:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 04:13:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:13:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:13:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:13:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
None
2020-04-16 04:13:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
None
2020-04-16 04:13:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
None
2020-04-16 04:13:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:13:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:13:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:13:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:13:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:13:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
None
2020-04-16 04:13:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
None
2020-04-16 04:13:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
None
2020-04-16 04:13:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:13:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:13:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:13:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
None
2020-04-16 04:13:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
None
2020-04-16 04:13:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
None
2020-04-16 04:13:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
None
2020-04-16 04:13:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
None
2020-04-16 04:13:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:13:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:13:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:13:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
None
2020-04-16 04:13:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
None
2020-04-16 04:13:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
None
2020-04-16 04:13:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:13:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
None
2020-04-16 04:13:57 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 04:13:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 1.408018,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 11, 13, 57, 983063),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/INFO': 10,
 'memusage/max': 55775232,
 'memusage/startup': 55775232,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 11, 13, 56, 575045)}
2020-04-16 04:13:57 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 04:14:44 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 04:14:44 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 04:14:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 04:14:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 04:14:44 [scrapy.extensions.telnet] INFO: Telnet Password: 08de47c19ad2f6d7
2020-04-16 04:14:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-04-16 04:14:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 04:14:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 04:14:44 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-16 04:14:44 [scrapy.core.engine] INFO: Spider opened
2020-04-16 04:14:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 04:14:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 04:14:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 04:14:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:14:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:14:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:14:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:14:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:14:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:14:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
None
2020-04-16 04:14:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
None
2020-04-16 04:14:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:14:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
None
2020-04-16 04:14:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:14:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:14:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:14:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
None
2020-04-16 04:14:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
None
2020-04-16 04:14:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
None
2020-04-16 04:14:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:14:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
None
2020-04-16 04:14:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
None
2020-04-16 04:14:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
None
2020-04-16 04:14:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
None
2020-04-16 04:14:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
None
2020-04-16 04:14:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:14:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
None
2020-04-16 04:14:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:14:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:14:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
None
2020-04-16 04:14:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:14:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
None
2020-04-16 04:14:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
None
2020-04-16 04:14:45 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 04:14:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 1.28083,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 11, 14, 45, 656499),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/INFO': 10,
 'memusage/max': 55521280,
 'memusage/startup': 55521280,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 11, 14, 44, 375669)}
2020-04-16 04:14:45 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 04:16:05 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 04:16:05 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 04:16:05 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 04:16:05 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 04:16:05 [scrapy.extensions.telnet] INFO: Telnet Password: 8c4a099fef08cfae
2020-04-16 04:16:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2020-04-16 04:16:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 04:16:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 04:16:05 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-16 04:16:05 [scrapy.core.engine] INFO: Spider opened
2020-04-16 04:16:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 04:16:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 04:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 04:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:05 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            '517I/Ohttps://events.google.com/io/\xa0'
            'GoogleI/O Live '
            'Widget/517-19I/Oyoutubef '
            'q '
            'https://events.google.com/io/widget/?utm_source=google&utm_medium=social&utm_campaign=gplus\xa0'
            '\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 31, in process_item
    self.cursor.execute(sql,[title,nvum,content])
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1146, "Table 'scary.wnagshangchonglang' doesn't exist")
2020-04-16 04:16:05 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Android  Android '
            'Android  Google '
            'Android Google  4 Google  10  '
            'Google Pixel  Android Nought  7%  '
            'Android 7.1  0.5%2015  Android 6.0  2014  '
            'Android 5.0  31.2%  32 % Android N Android O '
            'googleGoogle  Android N '
            ' Android O '
            ' Android '
            ' Android O  Android '
            'Google Project\xa0Treble Google  '
            'Project Treble  Android  OEM '
            'Android  Google '
            ' Android '
            'Android O  '
            '9to5google Google  '
            'Android  QualcomMediatek LG '
            ' Android '
            ' '
            'Android  Google Google '
            ' Google Pixel  Nexus  cdnforo Project Treble  '
            'Android Google '
            'Vendor '
            'ImplementaTIonOEM '
            ' '
            'AndroidfonpitOEM '
            'Google  OEM  '
            'Android AOSPOEM  '
            'Android  OEM  AndroidAndroid O '
            'Google Project Treble Android O Android '
            'Google I/O 2017  5  18 '
            'ifanrandroidcommunityhttp://www.ifanr.com/835683\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 31, in process_item
    self.cursor.execute(sql,[title,nvum,content])
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1146, "Table 'scary.wnagshangchonglang' doesn't exist")
2020-04-16 04:16:05 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Java  James Gosling\xa0 AWS '
            'James Gosling  Facebook  '
            'Gosling  AWS '
            'Gosling  IoT  IoT '
            'James Gosling  Sun Microsystems  Java '
            ' Sun  '
            'Google Liquid Robotics  Wave '
            'GliderGosling '
            ' '
            '\xa0'
            '[http://www.oschina.net]https://www.oschina.net/news/85108/aws-signs-java-father-james-gosling\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 31, in process_item
    self.cursor.execute(sql,[title,nvum,content])
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1146, "Table 'scary.wnagshangchonglang' doesn't exist")
2020-04-16 04:16:05 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'appAndroid '
            'batbatapphttps://green-android.org/app-convention.html\xa0'
            'AndroidAndroidAndroidAndroidAndroidAndroidGitHub '
            'issue trackerAndroidAndroid '
            'OAndroidTarget '
            'SDK Version >= 24 (Android 7.0)Project SvelteAndroid '
            '7READ_PHONE_STATEIMEIAndroid '
            '6.0Android\xa0'
            'SDKCPUIOCPUAlarmJobScheduler301CPUGoogleProject '
            'Volta121Android4.4 '
            '(Background-free)CPUIO '
            'Android O '
            '(Background-free)Android '
            'O3PendingIntentJobSchedulerAndroid '
            '5.0AndroidManifest.xmlAndroid '
            'OAndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xmlandroid.net.conn.CONNECTIVITY_CHANGE\xa0'
            'Android '
            '7android.hardware.action.NEW_PICTURE\xa0'
            'android.hardware.action.NEW_VIDEO\xa0'
            'android.net.wifi.SCAN_RESULTS\xa0 LocationManager '
            'android.intent.action.USER_PRESENT\xa0'
            'android.intent.action.ACTION_POWER_CONNECTED\xa0 '
            'JobScheduler '
            'android.intent.action.ACTION_POWER_DISCONNECTED\xa0 '
            'JobScheduler android.intent.action.MEDIA_\xa0'
            'AndroidAndroidManifest.xmlAndroid '
            '5.0AndroidManifext.xml<receiver\xa0...\xa0'
            'android:enabled="@bool/until_api_21">/src/main/res/values/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">true</bool>\n'
            '</resources>/src/main/res/values-v21/flags.xml<resources>\n'
            '\xa0\xa0<bool\xa0name="until_api_21">false</bool>\n'
            '</resources>Android 4.4 / '
            'AndroidAndroid '
            '4.4Storage Access '
            'FrameworkAPITFUSB '
            'OTGNASDropboxGoogle '
            'Drive4.4AndroidAndroid '
            '4.4<uses-permission '
            'android:name="android.permission.WRITE_EXTERNAL_STORAGE" '
            'android:maxSdkVersion="18" '
            '/>Context.getExternalFilesDir()\xa0'
            'Context.getExternalCacheDir()\xa0APIAndroid '
            '4.4Android '
            '4.4Google '
            'PlayGoogle PlayGoogle '
            'PlayAndroidAndroidGoogle '
            'PlayAndroidGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle '
            'PlayGoogle PlayGoogle '
            'PlayGoogle '
            'Play\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 31, in process_item
    self.cursor.execute(sql,[title,nvum,content])
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1146, "Table 'scary.wnagshangchonglang' doesn't exist")
2020-04-16 04:16:05 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Windows 10 SWindows '
            '10 Windows 10 SWindows RTWindows 10 '
            'SEdgeBingGoogle '
            'ChromeWindows StoreZDNetWindows '
            'StoreDekstop BridgeWindows '
            'StoreEdgeUWP '
            'EdgeHTMLJavaScriptWindows '
            'StoreWindows PlatformHTMLJavaScriptWindows '
            'StoreWindows '
            '10 '
            'ProiOSWebKitiOS '
            'ChromebookChromeGoogleChrome '
            'OSAndroidWindowsChromeFirefoxWindows '
            '10Windows 10 SChromebook '
            'EdgeChromeFirefoxcnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 31, in process_item
    self.cursor.execute(sql,[title,nvum,content])
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1146, "Table 'scary.wnagshangchonglang' doesn't exist")
2020-04-16 04:16:05 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  GMS '
            'OPPOvivoUnified '
            'Push '
            'ServiceUPSAPNS '
            'App  App '
            ' '
            'Android '
            'AppApp '
            'API  API '
            'AppSDKSDK '
            'ROM API '
            'SDKIT\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 31, in process_item
    self.cursor.execute(sql,[title,nvum,content])
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1146, "Table 'scary.wnagshangchonglang' doesn't exist")
2020-04-16 04:16:05 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t AndroidAndy '
            'RubinEssential PhoneEssential '
            'PhoneEssential '
            'PhoneEssential '
            'Phone8354GB128GB5.712560 x 1312 '
            'QHD19:103040mAh360UHD '
            '(3840x1920) 30Fps/DockEssential '
            'Phone1200 '
            '8004KEssential7.1.1ITEssential '
            'Phone3.5mmUSB-C5.069947893607495132 '
            'it\xa0http://mt.sohu.com/20170530/n495020791.shtml\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 31, in process_item
    self.cursor.execute(sql,[title,nvum,content])
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1146, "Table 'scary.wnagshangchonglang' doesn't exist")
2020-04-16 04:16:05 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Fuchsia Git '
            ' UI Android  '
            'Chrome OS Fuchsia  Linux    '
            '"Magenta" FuchsiaLinux  GPL \xa0'
            'BSD 3 clause,\xa0MIT, \xa0Apache 2.0\xa0 Linux '
            ' Android  Linux  Google Pixel '
            ' 2014  Linux Kernel 3.18 \xa0Magenta '
            ' Fuchsia '
            ' Android '
            'Fuchsia '
            "\xa0Google's Flutter SDK\xa0"
            ' Android  iOS Flutter app  Dart '
            'Flutter SDK "Escher"\xa0Vulkan '
            ' shadow-heavy Material Design '
            'Fuchsia  UI  ArmadilloFuchsia  Flutter '
            'SDK Armadillo  Google  Fuchsia '
            ' UI  Android APK  Android  UI '
            '20% '
            'Fuchsia  Fuchsia IRC Fuchsia  Travis '
            'Geiselbrecht  20% '
            'Android '
            ' UI  '
            'Dart  Linux  GPL Java \xa0'
            'Oracle  Android  '
            'Android  Fuchsia  2020 '
            'Fuchsia '
            'arsTECHNICAhttp://www.oschina.net/news/84594/google-fuchsia-smartphone-os-dumps-linux-has-a-wild-new-ui\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 31, in process_item
    self.cursor.execute(sql,[title,nvum,content])
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1146, "Table 'scary.wnagshangchonglang' doesn't exist")
2020-04-16 04:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:05 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'WannaCryWannaCry150NSAWannaCryNSA(moderate '
            'confidence)WannaCryWannaCryNSAIPLazarus '
            'GroupWannaCry300cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 31, in process_item
    self.cursor.execute(sql,[title,nvum,content])
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1146, "Table 'scary.wnagshangchonglang' doesn't exist")
2020-04-16 04:16:05 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t '
            'AOL50Oath15%35%Altaba19952261322AOL50Oath15%35%AltabaAltaba6002300Verizon200015%1995 '
            'David FiloCEO2001Terry '
            'Semel10001.62Verizon748.344.82300300200020125Tumblr2300254%1553.12112%Terry '
            'SemelCarol '
            'BartzFacebookInstagramSnapchat199532100022SlackWhatsAppVerizon*************************************************************323Verizon55106.5150YahooMozillaAppFantasy2012iOSAndroid41400SSLHTML5HTTPS5201320142Mavens '
            'GAAP2042%20122102011GAAP1510BrightRollFlurry1720127451805303501028.6427%IPO1.22IPO908FYIPB&JHackdays48%25%17.5770Yaho-o-ooMarissahttp://netsmell.com/post/yahoo-45b-acquired-by.html\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 31, in process_item
    self.cursor.execute(sql,[title,nvum,content])
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1146, "Table 'scary.wnagshangchonglang' doesn't exist")
2020-04-16 04:16:05 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t MinecraftXbox One '
            'X4K.jpgE3 '
            '2017MinecraftGears of War 4Forza '
            'Horizon 3Killer InstinctHalo Wars 24KSuper Duper '
            'Graphics...XD4K '
            '... 4K '
            'Better '
            'TogetherMinecraftMinecraftSuper '
            'Duper Graphics packXbox One '
            'X4KPCMinecraftMinecraftMinecraftSkinMinecraft\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 31, in process_item
    self.cursor.execute(sql,[title,nvum,content])
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1146, "Table 'scary.wnagshangchonglang' doesn't exist")
2020-04-16 04:16:05 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t splash '
            'screenappappAndroid '
            'Oreo\xa0Android 8.0\xa0\xa0splash screen '
            'APIAPIdrawableappActivityAndroid '
            'OreodrawableSplashActivityAPI\xa0'
            'Android Developers\xa0'
            '413AOSPAndroid '
            'O\xa0AOSP commit\xa0'
            'APIAndroid '
            'Oreo\xa0APIAndroid '
            'Open Source ProjectAndroid Oreo Adds a Splash Screen API so '
            'Developers can Easily Build App Loading Screens\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 31, in process_item
    self.cursor.execute(sql,[title,nvum,content])
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1146, "Table 'scary.wnagshangchonglang' doesn't exist")
2020-04-16 04:16:05 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t  bug  Play store  app '
            'bugapp\xa0'
            'HackerOne '
            'issue1000app\xa0'
            'Dropbox, Duolingo, Line, Snapchat, Tinder, Alibaba, Mail.ru  '
            'Headspace '
            'appappappbughttps://www.engadget.com/2017/10/20/google-bug-bounty-program-android-apps/\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 31, in process_item
    self.cursor.execute(sql,[title,nvum,content])
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1146, "Table 'scary.wnagshangchonglang' doesn't exist")
2020-04-16 04:16:05 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t Google  Android 8.0 '
            'Oreo Android Beta Google  Oreo '
            'Google  Nexus  Pixel  '
            'Android 8.0 Google  '
            'EssentialHTCKyoceraMotorolaHMD '
            'GlobalNokia '
            'Android 8.0  2018  Pixel  '
            'HTC  LG  HTC  U11  Android '
            '8.0cnBeta.COM\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 31, in process_item
    self.cursor.execute(sql,[title,nvum,content])
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1146, "Table 'scary.wnagshangchonglang' doesn't exist")
2020-04-16 04:16:05 [scrapy.core.scraper] ERROR: Error processing {'content': ' \n'
            '\t\t\t\t\t \n'
            '\t\t\t\t\t\t\n'
            '\t\t\t\t\t\n'
            '\t\t\t\t\t \xa0 \xa0 \xa0 \xa0'
            'GoogleUdacity75000AndroidGoogleUdacity20152016100010000Google '
            'EMEAMatt '
            'BrittinUdacity75000Google202050AndroidWebUdacity15000cnbetahttp://www.cnbeta.com/articles/tech/648715.htm\xa0\n'
            '\t\t\t\t',
 'nvum': '1113',
 'title': 'Fuchsia Linux UI'}
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/pipelines.py", line 31, in process_item
    self.cursor.execute(sql,[title,nvum,content])
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1146, "Table 'scary.wnagshangchonglang' doesn't exist")
2020-04-16 04:16:05 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 04:16:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 0.698255,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 11, 16, 5, 802962),
 'log_count/DEBUG': 16,
 'log_count/ERROR': 15,
 'log_count/INFO': 10,
 'memusage/max': 55353344,
 'memusage/startup': 55353344,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 11, 16, 5, 104707)}
2020-04-16 04:16:05 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-16 04:16:43 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-16 04:16:43 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-16 04:16:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-16 04:16:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-16 04:16:43 [scrapy.extensions.telnet] INFO: Telnet Password: 012d7a17f8c8d3b5
2020-04-16 04:16:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage']
2020-04-16 04:16:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-16 04:16:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-16 04:16:43 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-16 04:16:43 [scrapy.core.engine] INFO: Spider opened
2020-04-16 04:16:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-16 04:16:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-16 04:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-16 04:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
None
2020-04-16 04:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
None
2020-04-16 04:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
None
2020-04-16 04:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
None
2020-04-16 04:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
None
2020-04-16 04:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
None
2020-04-16 04:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
None
2020-04-16 04:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
None
2020-04-16 04:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
None
2020-04-16 04:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
None
2020-04-16 04:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
None
2020-04-16 04:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
None
2020-04-16 04:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-16 04:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
None
2020-04-16 04:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
None
2020-04-16 04:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
None
2020-04-16 04:16:44 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-16 04:16:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 0.79024,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 16, 11, 16, 44, 703953),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/INFO': 10,
 'memusage/max': 55693312,
 'memusage/startup': 55693312,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 16, 11, 16, 43, 913713)}
2020-04-16 04:16:44 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-17 02:33:49 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-17 02:33:49 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-17 02:33:49 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-17 02:33:54 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-17 02:33:54 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-17 02:33:54 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-17 02:33:58 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-17 02:33:58 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-17 02:33:58 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-17 02:34:06 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-17 02:34:06 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-17 02:34:06 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-17 02:34:06 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-17 02:34:06 [scrapy.extensions.telnet] INFO: Telnet Password: dcac0ec6ed7f418a
2020-04-17 02:34:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2020-04-17 02:34:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-17 02:34:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-17 02:34:07 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-17 02:34:07 [scrapy.core.engine] INFO: Spider opened
2020-04-17 02:34:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-17 02:34:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-17 02:34:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-17 02:34:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 117, in iter_errback
    yield next(it)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 40, in parse
    next = response.xpath("//div[@class='paginate-container']//ul//li[last()-2]/a/@href").extrua_first()
AttributeError: 'SelectorList' object has no attribute 'extrua_first'
2020-04-17 02:34:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:34:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:34:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:34:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:34:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:34:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
None
2020-04-17 02:34:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
None
2020-04-17 02:34:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
None
2020-04-17 02:34:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
None
2020-04-17 02:34:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
None
2020-04-17 02:34:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:34:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:34:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:34:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:34:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:34:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
None
2020-04-17 02:34:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
None
2020-04-17 02:34:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
None
2020-04-17 02:34:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
None
2020-04-17 02:34:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
None
2020-04-17 02:34:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:34:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
None
2020-04-17 02:34:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:34:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
None
2020-04-17 02:34:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:34:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
None
2020-04-17 02:34:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:34:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
None
2020-04-17 02:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
None
2020-04-17 02:34:17 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-17 02:34:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 10.519285,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 17, 9, 34, 17, 895856),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 55750656,
 'memusage/startup': 55750656,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 4, 17, 9, 34, 7, 376571)}
2020-04-17 02:34:17 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-17 02:35:04 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-17 02:35:04 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-17 02:35:04 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-17 02:35:04 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-17 02:35:04 [scrapy.extensions.telnet] INFO: Telnet Password: 15d04ae6ce649faf
2020-04-17 02:35:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-04-17 02:35:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-17 02:35:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-17 02:35:04 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-17 02:35:04 [scrapy.core.engine] INFO: Spider opened
2020-04-17 02:35:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-17 02:35:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-17 02:35:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-17 02:35:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 117, in iter_errback
    yield next(it)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 40, in parse
    next = response.xpath("//div[@class='paginate-container']//ul//li[last()-2]/a/@href").extra_first()
AttributeError: 'SelectorList' object has no attribute 'extra_first'
2020-04-17 02:35:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
None
2020-04-17 02:35:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
None
2020-04-17 02:35:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
None
2020-04-17 02:35:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
None
2020-04-17 02:35:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
None
2020-04-17 02:35:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
None
2020-04-17 02:35:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
None
2020-04-17 02:35:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
None
2020-04-17 02:35:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
None
2020-04-17 02:35:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
None
2020-04-17 02:35:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
None
2020-04-17 02:35:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
None
2020-04-17 02:35:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
None
2020-04-17 02:35:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
None
2020-04-17 02:35:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
None
2020-04-17 02:35:05 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-17 02:35:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 1.164057,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 17, 9, 35, 5, 372626),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 55341056,
 'memusage/startup': 55341056,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 4, 17, 9, 35, 4, 208569)}
2020-04-17 02:35:05 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-17 02:35:44 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-17 02:35:44 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-17 02:35:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-17 02:35:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-17 02:35:44 [scrapy.extensions.telnet] INFO: Telnet Password: 6afce985811e3280
2020-04-17 02:35:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage']
2020-04-17 02:35:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-17 02:35:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-17 02:35:44 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-17 02:35:44 [scrapy.core.engine] INFO: Spider opened
2020-04-17 02:35:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-17 02:35:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-17 02:35:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-17 02:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
None
2020-04-17 02:35:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
None
2020-04-17 02:35:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
None
2020-04-17 02:35:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
None
2020-04-17 02:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
None
2020-04-17 02:35:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
None
2020-04-17 02:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
None
2020-04-17 02:35:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
None
2020-04-17 02:35:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
None
2020-04-17 02:35:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
None
2020-04-17 02:35:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
None
2020-04-17 02:35:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
None
2020-04-17 02:35:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
None
2020-04-17 02:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
None
2020-04-17 02:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:35:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
None
2020-04-17 02:35:45 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-17 02:35:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 1.213962,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 17, 9, 35, 45, 889416),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/INFO': 10,
 'memusage/max': 55205888,
 'memusage/startup': 55205888,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2020, 4, 17, 9, 35, 44, 675454)}
2020-04-17 02:35:45 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-17 02:38:29 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-17 02:38:29 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-17 02:38:29 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-17 02:38:29 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-17 02:38:29 [scrapy.extensions.telnet] INFO: Telnet Password: 97b95bd709abfa23
2020-04-17 02:38:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-04-17 02:38:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-17 02:38:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-17 02:38:29 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-17 02:38:29 [scrapy.core.engine] INFO: Spider opened
2020-04-17 02:38:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-17 02:38:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-17 02:38:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-17 02:38:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 117, in iter_errback
    yield next(it)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 41, in parse
    if next.startrswich('.'):
AttributeError: 'str' object has no attribute 'startrswich'
2020-04-17 02:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:38:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
None
2020-04-17 02:38:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
None
2020-04-17 02:38:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
None
2020-04-17 02:38:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
None
2020-04-17 02:38:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
None
2020-04-17 02:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:38:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
None
2020-04-17 02:38:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
None
2020-04-17 02:38:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
None
2020-04-17 02:38:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
None
2020-04-17 02:38:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
None
2020-04-17 02:38:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
None
2020-04-17 02:38:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
None
2020-04-17 02:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:38:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
None
2020-04-17 02:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:38:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
None
2020-04-17 02:38:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:38:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
None
2020-04-17 02:38:42 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-17 02:38:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 12.830166,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 17, 9, 38, 42, 656321),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 54996992,
 'memusage/startup': 54996992,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 4, 17, 9, 38, 29, 826155)}
2020-04-17 02:38:42 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-17 02:40:48 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-17 02:40:48 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-17 02:40:48 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-17 02:40:48 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-17 02:40:48 [scrapy.extensions.telnet] INFO: Telnet Password: 65962e0220d84b15
2020-04-17 02:40:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage']
2020-04-17 02:40:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-17 02:40:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-17 02:40:48 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-17 02:40:48 [scrapy.core.engine] INFO: Spider opened
2020-04-17 02:40:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-17 02:40:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-17 02:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-17 02:40:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
Traceback (most recent call last):
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/defer.py", line 117, in iter_errback
    yield next(it)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/utils/python.py", line 345, in __next__
    return next(self.data)
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/mrxu/.virtualenvs/spider/lib/python3.5/site-packages/scrapy/core/spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "/home/mrxu/PycharmProjects/scarty/paoborizi/paoborizi/spiders/paobao.py", line 41, in parse
    if next.startswich('.'):
AttributeError: 'str' object has no attribute 'startswich'
2020-04-17 02:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:40:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
None
2020-04-17 02:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:40:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
None
2020-04-17 02:40:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
None
2020-04-17 02:40:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
None
2020-04-17 02:40:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
None
2020-04-17 02:40:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
None
2020-04-17 02:40:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
None
2020-04-17 02:40:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
None
2020-04-17 02:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:40:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
None
2020-04-17 02:40:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
None
2020-04-17 02:40:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
None
2020-04-17 02:40:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
None
2020-04-17 02:40:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
None
2020-04-17 02:40:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
None
2020-04-17 02:40:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
None
2020-04-17 02:40:48 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-17 02:40:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5093,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 143586,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 16,
 'elapsed_time_seconds': 0.658916,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 17, 9, 40, 48, 883763),
 'item_scraped_count': 15,
 'log_count/DEBUG': 31,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 55631872,
 'memusage/startup': 55631872,
 'request_depth_max': 1,
 'response_received_count': 16,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 4, 17, 9, 40, 48, 224847)}
2020-04-17 02:40:48 [scrapy.core.engine] INFO: Spider closed (finished)
2020-04-17 02:41:31 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: paoborizi)
2020-04-17 02:41:31 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.5.2 (default, Oct  8 2019, 13:06:37) - [GCC 5.4.0 20160609], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-96-generic-x86_64-with-Ubuntu-16.04-xenial
2020-04-17 02:41:31 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-17 02:41:31 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'paoborizi',
 'LOG_FILE': 'paoba.log',
 'NEWSPIDER_MODULE': 'paoborizi.spiders',
 'SPIDER_MODULES': ['paoborizi.spiders']}
2020-04-17 02:41:31 [scrapy.extensions.telnet] INFO: Telnet Password: 4355792665a783c2
2020-04-17 02:41:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2020-04-17 02:41:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-17 02:41:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-17 02:41:31 [scrapy.middleware] INFO: Enabled item pipelines:
['paoborizi.pipelines.PaoboriziPipeline']
2020-04-17 02:41:31 [scrapy.core.engine] INFO: Spider opened
2020-04-17 02:41:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-17 02:41:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-04-17 02:41:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4.html> (referer: None)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_2.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/1023/8634.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0511/7937.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0509/7929.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0510/7936.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7945.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0523/7968.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0515/7947.html>
None
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8085.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0906/8478.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0822/8404.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0531/8024.html>
None
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2016/1118/6786.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_2.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_3.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_2.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/1212/6845.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_2.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0119/7060.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_2.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0123/7089.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_2.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2016/1118/6786.html>
None
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0210/7098.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_2.html)
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/1212/6845.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0119/7060.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0123/7089.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0605/8037.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8084.html>
None
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0405/7781.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_2.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0405/7782.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_2.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0418/7844.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_2.html)
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0210/7098.html>
None
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0411/7809.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_2.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0420/7859.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_2.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0505/7914.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_2.html)
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0405/7781.html>
None
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0506/7915.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_2.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2017/0425/7871.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_2.html)
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0405/7782.html>
None
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0507/7918.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_2.html)
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0418/7844.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0411/7809.html>
None
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_4.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_3.html)
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0420/7859.html>
None
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0419/4161.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_3.html)
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0505/7914.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0506/7915.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2017/0425/7871.html>
None
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2016/0527/4303.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_3.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2016/0519/4282.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_3.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2016/0531/4315.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_3.html)
2020-04-17 02:41:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2016/0519/4275.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_3.html)
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0507/7918.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0419/4161.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2016/0527/4303.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2016/0519/4282.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2016/0531/4315.html>
None
2020-04-17 02:41:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2016/0519/4275.html>
None
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0822/6558.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_3.html)
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0816/6547.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_3.html)
2020-04-17 02:41:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0822/6558.html>
None
2020-04-17 02:41:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0816/6547.html>
None
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2016/1002/6655.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_3.html)
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2016/1002/6654.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_3.html)
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/1003/6657.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_3.html)
2020-04-17 02:41:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2017/0617/8086.html>
None
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/1116/6782.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_3.html)
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/1008/6662.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_3.html)
2020-04-17 02:41:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2016/1002/6655.html>
None
2020-04-17 02:41:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2016/1002/6654.html>
None
2020-04-17 02:41:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/1003/6657.html>
None
2020-04-17 02:41:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/1116/6782.html>
None
2020-04-17 02:41:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/1008/6662.html>
None
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_5.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_4.html)
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0602/4321.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_3.html)
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/1125/3721.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_4.html)
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/1117/3699.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_4.html)
2020-04-17 02:41:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0602/4321.html>
None
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/1230/3816.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_4.html)
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0114/3867.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_4.html)
2020-04-17 02:41:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/1125/3721.html>
None
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0104/3823.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_4.html)
2020-04-17 02:41:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/1117/3699.html>
None
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2016/0118/3883.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_4.html)
2020-04-17 02:41:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/1230/3816.html>
None
2020-04-17 02:41:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0114/3867.html>
None
2020-04-17 02:41:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0104/3823.html>
None
2020-04-17 02:41:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2016/0118/3883.html>
None
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2016/0126/3913.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_4.html)
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2016/0216/3966.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_4.html)
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2016/0221/3986.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_4.html)
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2016/0602/4327.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_3.html)
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0602/4328.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_3.html)
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2016/0310/4045.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_4.html)
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2016/0226/3999.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_4.html)
2020-04-17 02:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_6.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_5.html)
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2016/0126/3913.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2016/0216/3966.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2016/0221/3986.html>
None
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0824/3359.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_5.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0902/3405.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_5.html)
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2016/0602/4327.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0602/4328.html>
None
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/0920/3481.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_5.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0905/3422.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_5.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/0922/3496.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_5.html)
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2016/0310/4045.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2016/0226/3999.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0824/3359.html>
None
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/1009/3559.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_5.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0924/3511.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_5.html)
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0902/3405.html>
None
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2015/1020/3603.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_5.html)
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/0920/3481.html>
None
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/1020/3602.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_5.html)
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0905/3422.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/0922/3496.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/1009/3559.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0924/3511.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2015/1020/3603.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/1020/3602.html>
None
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2016/1214/6863.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_2.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/1024/3617.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_5.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2015/1021/3604.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_5.html)
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2016/1214/6863.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/1024/3617.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2015/1021/3604.html>
None
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/1030/3637.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_5.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/1104/3654.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_5.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/1110/3666.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_5.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0317/4063.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_4.html)
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/1030/3637.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/1104/3654.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/1110/3666.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0317/4063.html>
None
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0329/4100.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_4.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0417/4156.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_4.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/1203/3744.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_4.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_7.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_6.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0607/3010.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_6.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0609/3021.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_6.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2015/1017/3590.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_5.html)
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0329/4100.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2016/0417/4156.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/1203/3744.html>
None
2020-04-17 02:41:34 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.jcodecraeer.com//> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0607/3010.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0609/3021.html>
None
2020-04-17 02:41:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/yidonghulian/2015/1017/3590.html>
None
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/0623/3098.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_6.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0710/3171.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_6.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0704/3135.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_6.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0708/3162.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_6.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/0625/3112.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_6.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0625/3106.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_6.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4.html)
2020-04-17 02:41:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0711/3172.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_6.html)
2020-04-17 02:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0728/3225.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_6.html)
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/0623/3098.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0710/3171.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0704/3135.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0708/3162.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/0625/3112.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0625/3106.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2017/0831/8452.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0711/3172.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0728/3225.html>
None
2020-04-17 02:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/0811/3285.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_6.html)
2020-04-17 02:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0818/3319.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_6.html)
2020-04-17 02:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0802/3250.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_6.html)
2020-04-17 02:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0519/2893.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_7.html)
2020-04-17 02:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0815/3307.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_6.html)
2020-04-17 02:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0522/2914.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_7.html)
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/0811/3285.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0818/3319.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0802/3250.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0519/2893.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0815/3307.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0522/2914.html>
None
2020-04-17 02:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0527/2937.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_7.html)
2020-04-17 02:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0601/2972.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_7.html)
2020-04-17 02:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0527/2940.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_7.html)
2020-04-17 02:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/0528/2947.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_7.html)
2020-04-17 02:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/0603/2984.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_7.html)
2020-04-17 02:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0524/2922.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_7.html)
2020-04-17 02:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com//> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_7.html)
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0527/2937.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0601/2972.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0527/2940.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/0528/2947.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/waiwenfanyi/2015/0603/2984.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/anzhuokaifa/anzhuozixun/2015/0524/2922.html>
None
2020-04-17 02:41:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com//>
None
2020-04-17 02:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.jcodecraeer.com/a/wangzhantuijian/shejiaowangluo/2015/0612/3036.html> (referer: http://www.jcodecraeer.com/plus/list_tid_4_TotalResult_596_PageNo_6.html)
2020-04-17 02:41:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.jcodecraeer.com/a/wangzhantuijian/shejiaowangluo/2015/0612/3036.html>
None
2020-04-17 02:41:36 [scrapy.core.engine] INFO: Closing spider (finished)
2020-04-17 02:41:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 36448,
 'downloader/request_count': 106,
 'downloader/request_method_count/GET': 106,
 'downloader/response_bytes': 986579,
 'downloader/response_count': 106,
 'downloader/response_status_count/200': 106,
 'dupefilter/filtered': 6,
 'elapsed_time_seconds': 4.399267,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 4, 17, 9, 41, 36, 14234),
 'item_scraped_count': 99,
 'log_count/DEBUG': 206,
 'log_count/INFO': 10,
 'memusage/max': 55816192,
 'memusage/startup': 55816192,
 'request_depth_max': 7,
 'response_received_count': 106,
 'scheduler/dequeued': 106,
 'scheduler/dequeued/memory': 106,
 'scheduler/enqueued': 106,
 'scheduler/enqueued/memory': 106,
 'start_time': datetime.datetime(2020, 4, 17, 9, 41, 31, 614967)}
2020-04-17 02:41:36 [scrapy.core.engine] INFO: Spider closed (finished)
